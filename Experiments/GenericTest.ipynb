{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "# from HDGeneric import NeuralHD\n",
    "# from testcode import NeuralHD2\n",
    "from NeuralHDv2 import NeuralHDv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"../../../Data/malware-classification/\"\n",
    "with open(path+'data11.npy', 'rb') as f:\n",
    "    transxtrain=np.load(f)\n",
    "    transx_test=np.load(f)\n",
    "    transytrain=np.load(f)\n",
    "    transy_test=np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtr=torch.from_numpy(transxtrain).float()\n",
    "xte=torch.from_numpy(transx_test).float()\n",
    "ytr=torch.from_numpy(transytrain).long()\n",
    "yte=torch.from_numpy(transy_test).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bobbymissirian/Files/Research/Cybersecurity/Experiments/NeuralHDv1.py:53: UserWarning: An output with one or more elements was resized since it had shape [257, 1024], which does not match the required output shape [184, 1024].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  torch.matmul(x[i:i+bsize], self.basis.T, out=temp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7588)\n",
      "1\n",
      "tensor(0.8409)\n",
      "1\n",
      "tensor(0.8474)\n",
      "1\n",
      "tensor(0.8633)\n",
      "1\n",
      "tensor(0.8715)\n",
      "1\n",
      "tensor(0.8573)\n",
      "1\n",
      "tensor(0.8785)\n",
      "1\n",
      "tensor(0.8922)\n",
      "1\n",
      "tensor(0.8792)\n",
      "1\n",
      "tensor(0.8771)\n",
      "1\n",
      "tensor(0.8825)\n",
      "1\n",
      "tensor(0.8931)\n",
      "1\n",
      "tensor(0.8718)\n",
      "1\n",
      "tensor(0.9362)\n",
      "1\n",
      "tensor(0.9352)\n",
      "1\n",
      "tensor(0.9479)\n",
      "1\n",
      "tensor(0.9459)\n",
      "1\n",
      "tensor(0.9455)\n",
      "1\n",
      "tensor(0.9464)\n",
      "1\n",
      "tensor(0.9434)\n",
      "1\n",
      "tensor(0.9410)\n",
      "1\n",
      "tensor(0.9448)\n",
      "1\n",
      "tensor(0.9449)\n",
      "1\n",
      "tensor(0.9437)\n",
      "1\n",
      "tensor(0.9417)\n",
      "1\n",
      "tensor(0.9410)\n",
      "1\n",
      "tensor(0.9439)\n",
      "1\n",
      "tensor(0.9488)\n",
      "1\n",
      "tensor(0.9507)\n",
      "1\n",
      "tensor(0.9510)\n",
      "1\n",
      "tensor(0.9528)\n",
      "1\n",
      "tensor(0.9487)\n",
      "1\n",
      "tensor(0.9444)\n",
      "1\n",
      "tensor(0.9474)\n",
      "1\n",
      "tensor(0.9504)\n",
      "1\n",
      "tensor(0.9528)\n",
      "1\n",
      "tensor(0.9492)\n",
      "1\n",
      "tensor(0.9422)\n",
      "1\n",
      "tensor(0.9492)\n",
      "1\n",
      "tensor(0.9481)\n",
      "1\n",
      "tensor(0.9431)\n",
      "1\n",
      "tensor(0.9513)\n",
      "1\n",
      "tensor(0.9443)\n",
      "1\n",
      "tensor(0.9459)\n",
      "1\n",
      "tensor(0.9468)\n",
      "1\n",
      "tensor(0.9499)\n",
      "1\n",
      "tensor(0.9515)\n",
      "1\n",
      "tensor(0.9526)\n",
      "1\n",
      "tensor(0.9490)\n",
      "1\n",
      "tensor(0.9470)\n",
      "1\n",
      "tensor(0.9499)\n",
      "1\n",
      "tensor(0.9492)\n",
      "1\n",
      "tensor(0.9542)\n",
      "1\n",
      "tensor(0.9457)\n",
      "1\n",
      "tensor(0.9508)\n",
      "1\n",
      "tensor(0.9491)\n",
      "1\n",
      "tensor(0.9508)\n",
      "1\n",
      "tensor(0.9417)\n",
      "1\n",
      "tensor(0.9509)\n",
      "1\n",
      "tensor(0.9495)\n",
      "1\n",
      "tensor(0.9490)\n",
      "1\n",
      "tensor(0.9508)\n",
      "1\n",
      "tensor(0.9490)\n",
      "1\n",
      "tensor(0.9537)\n",
      "1\n",
      "tensor(0.9563)\n",
      "1\n",
      "tensor(0.9487)\n",
      "1\n",
      "tensor(0.9544)\n",
      "1\n",
      "tensor(0.9460)\n",
      "1\n",
      "tensor(0.9513)\n",
      "1\n",
      "tensor(0.9480)\n",
      "1\n",
      "tensor(0.9487)\n",
      "1\n",
      "tensor(0.9415)\n",
      "1\n",
      "tensor(0.9536)\n",
      "1\n",
      "tensor(0.8912)\n",
      "1\n",
      "tensor(0.9557)\n"
     ]
    }
   ],
   "source": [
    "model=NeuralHDv2(classes =9, features =257, dim = 1024, batch_size=64,lr=.0001)\n",
    "model.fit(xtr[:int(transxtrain.shape[0]*1),:],ytr[:int(transxtrain.shape[0]*1)],15,4,.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 0, 8, ..., 1, 1, 6])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(transx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
