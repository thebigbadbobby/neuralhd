{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "# from HDGeneric import NeuralHD\n",
    "# from testcode import NeuralHD2\n",
    "from MLP import MLP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"../../../Data/malware-classification/\"\n",
    "with open(path+'data11.npy', 'rb') as f:\n",
    "    transxtrain=np.load(f)\n",
    "    transx_test=np.load(f)\n",
    "    transytrain=np.load(f)\n",
    "    transy_test=np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtr=torch.from_numpy(transxtrain).float()\n",
    "xte=torch.from_numpy(transx_test).float()\n",
    "ytr=torch.from_numpy(transytrain).long()\n",
    "yte=torch.from_numpy(transy_test).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 257)               66306     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               25800     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 9)                 909       \n",
      "=================================================================\n",
      "Total params: 93,015\n",
      "Trainable params: 93,015\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(8151, 257) (8151, 9)\n",
      "Epoch 1/75\n",
      "66/66 [==============================] - 1s 5ms/step - loss: 1.3162 - accuracy: 0.6141 - val_loss: 0.9545 - val_accuracy: 0.7474\n",
      "Epoch 2/75\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.8259 - accuracy: 0.7583 - val_loss: 0.8087 - val_accuracy: 0.7584\n",
      "Epoch 3/75\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.7982 - val_loss: 0.6918 - val_accuracy: 0.7872\n",
      "Epoch 4/75\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.6069 - accuracy: 0.8204 - val_loss: 0.6313 - val_accuracy: 0.8363\n",
      "Epoch 5/75\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.5423 - accuracy: 0.8429 - val_loss: 0.5663 - val_accuracy: 0.8394\n",
      "Epoch 6/75\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.8572 - val_loss: 0.5277 - val_accuracy: 0.8492\n",
      "Epoch 7/75\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.8727 - val_loss: 0.4731 - val_accuracy: 0.8565\n",
      "Epoch 8/75\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.3777 - accuracy: 0.9026 - val_loss: 0.4331 - val_accuracy: 0.9013\n",
      "Epoch 9/75\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.3402 - accuracy: 0.9149 - val_loss: 0.4066 - val_accuracy: 0.8970\n",
      "Epoch 10/75\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.3118 - accuracy: 0.9213 - val_loss: 0.4029 - val_accuracy: 0.9013\n",
      "Epoch 11/75\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2885 - accuracy: 0.9259 - val_loss: 0.3522 - val_accuracy: 0.9129\n",
      "Epoch 12/75\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2699 - accuracy: 0.9294 - val_loss: 0.3571 - val_accuracy: 0.9129\n",
      "Epoch 13/75\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2539 - accuracy: 0.9327 - val_loss: 0.3433 - val_accuracy: 0.8921\n",
      "Epoch 14/75\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2434 - accuracy: 0.9350 - val_loss: 0.3124 - val_accuracy: 0.9178\n",
      "Epoch 15/75\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2306 - accuracy: 0.9396 - val_loss: 0.3020 - val_accuracy: 0.9203\n",
      "Epoch 16/75\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2218 - accuracy: 0.9406 - val_loss: 0.3143 - val_accuracy: 0.9111\n",
      "Epoch 17/75\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2120 - accuracy: 0.9397 - val_loss: 0.3143 - val_accuracy: 0.9203\n",
      "Epoch 18/75\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.2050 - accuracy: 0.9417 - val_loss: 0.2944 - val_accuracy: 0.9246\n",
      "Epoch 19/75\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.1980 - accuracy: 0.9446 - val_loss: 0.2793 - val_accuracy: 0.9264\n",
      "Epoch 20/75\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.1916 - accuracy: 0.9451 - val_loss: 0.3722 - val_accuracy: 0.8903\n",
      "Epoch 21/75\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.1858 - accuracy: 0.9471 - val_loss: 0.2746 - val_accuracy: 0.9295\n",
      "Epoch 22/75\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.9497 - val_loss: 0.2600 - val_accuracy: 0.9362\n",
      "Epoch 23/75\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.1737 - accuracy: 0.9508 - val_loss: 0.3392 - val_accuracy: 0.9166\n",
      "Epoch 24/75\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.1706 - accuracy: 0.9514 - val_loss: 0.3121 - val_accuracy: 0.9270\n",
      "Epoch 25/75\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.1658 - accuracy: 0.9506 - val_loss: 0.3067 - val_accuracy: 0.9080\n",
      "Epoch 26/75\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.1599 - accuracy: 0.9544 - val_loss: 0.3715 - val_accuracy: 0.9148\n",
      "Epoch 27/75\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.1577 - accuracy: 0.9538 - val_loss: 0.3088 - val_accuracy: 0.9191\n",
      "Epoch 28/75\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.1542 - accuracy: 0.9552 - val_loss: 0.3802 - val_accuracy: 0.9185\n",
      "Epoch 29/75\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.1502 - accuracy: 0.9561 - val_loss: 0.2764 - val_accuracy: 0.9356\n",
      "Epoch 30/75\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.1476 - accuracy: 0.9583 - val_loss: 0.2817 - val_accuracy: 0.9375\n",
      "Epoch 31/75\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.1423 - accuracy: 0.9586 - val_loss: 0.3322 - val_accuracy: 0.9111\n",
      "Epoch 32/75\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.1394 - accuracy: 0.9601 - val_loss: 0.2835 - val_accuracy: 0.9283\n",
      "Epoch 33/75\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.1355 - accuracy: 0.9606 - val_loss: 0.2549 - val_accuracy: 0.9375\n",
      "Epoch 34/75\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.1340 - accuracy: 0.9630 - val_loss: 0.2692 - val_accuracy: 0.9405\n",
      "Epoch 35/75\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.1306 - accuracy: 0.9629 - val_loss: 0.2612 - val_accuracy: 0.9368\n",
      "Epoch 36/75\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.1271 - accuracy: 0.9637 - val_loss: 0.2718 - val_accuracy: 0.9319\n",
      "Epoch 37/75\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.1270 - accuracy: 0.9626 - val_loss: 0.2718 - val_accuracy: 0.9405\n",
      "Epoch 38/75\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.1231 - accuracy: 0.9653 - val_loss: 0.2670 - val_accuracy: 0.9356\n",
      "Epoch 39/75\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.1217 - accuracy: 0.9675 - val_loss: 0.3901 - val_accuracy: 0.9007\n",
      "Epoch 40/75\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.1208 - accuracy: 0.9660 - val_loss: 0.2823 - val_accuracy: 0.9375\n",
      "Epoch 41/75\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.1153 - accuracy: 0.9675 - val_loss: 0.2644 - val_accuracy: 0.9405\n",
      "Epoch 42/75\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.1145 - accuracy: 0.9679 - val_loss: 0.2547 - val_accuracy: 0.9411\n",
      "Epoch 43/75\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.1111 - accuracy: 0.9673 - val_loss: 0.3155 - val_accuracy: 0.9246\n",
      "Epoch 44/75\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.1101 - accuracy: 0.9681 - val_loss: 0.2792 - val_accuracy: 0.9387\n",
      "Epoch 45/75\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.1065 - accuracy: 0.9701 - val_loss: 0.2608 - val_accuracy: 0.9405\n",
      "Epoch 46/75\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.1054 - accuracy: 0.9707 - val_loss: 0.2591 - val_accuracy: 0.9528\n",
      "Epoch 47/75\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.1045 - accuracy: 0.9721 - val_loss: 0.2847 - val_accuracy: 0.9491\n",
      "Epoch 48/75\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.1030 - accuracy: 0.9727 - val_loss: 0.2771 - val_accuracy: 0.9411\n",
      "Epoch 49/75\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.1004 - accuracy: 0.9722 - val_loss: 0.2687 - val_accuracy: 0.9497\n",
      "Epoch 50/75\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.0991 - accuracy: 0.9736 - val_loss: 0.2619 - val_accuracy: 0.9510\n",
      "Epoch 51/75\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.0957 - accuracy: 0.9744 - val_loss: 0.2731 - val_accuracy: 0.9540\n",
      "Epoch 52/75\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.0958 - accuracy: 0.9744 - val_loss: 0.4399 - val_accuracy: 0.8988\n",
      "Epoch 53/75\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0948 - accuracy: 0.9748 - val_loss: 0.2592 - val_accuracy: 0.9503\n",
      "Epoch 54/75\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.0902 - accuracy: 0.9758 - val_loss: 0.3314 - val_accuracy: 0.9387\n",
      "Epoch 55/75\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.0903 - accuracy: 0.9773 - val_loss: 0.2638 - val_accuracy: 0.9430\n",
      "Epoch 56/75\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.0911 - accuracy: 0.9756 - val_loss: 0.2470 - val_accuracy: 0.9565\n",
      "Epoch 57/75\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.0870 - accuracy: 0.9782 - val_loss: 0.2695 - val_accuracy: 0.9485\n",
      "Epoch 58/75\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.0879 - accuracy: 0.9773 - val_loss: 0.2459 - val_accuracy: 0.9583\n",
      "Epoch 59/75\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.0834 - accuracy: 0.9788 - val_loss: 0.2791 - val_accuracy: 0.9454\n",
      "Epoch 60/75\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.0834 - accuracy: 0.9782 - val_loss: 0.2645 - val_accuracy: 0.9510\n",
      "Epoch 61/75\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.0842 - accuracy: 0.9770 - val_loss: 0.2742 - val_accuracy: 0.9540\n",
      "Epoch 62/75\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.0831 - accuracy: 0.9784 - val_loss: 0.2603 - val_accuracy: 0.9528\n",
      "Epoch 63/75\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0792 - accuracy: 0.9790 - val_loss: 0.3099 - val_accuracy: 0.9368\n",
      "Epoch 64/75\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0799 - accuracy: 0.9791 - val_loss: 0.2995 - val_accuracy: 0.9338\n",
      "Epoch 65/75\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0761 - accuracy: 0.9799 - val_loss: 0.2579 - val_accuracy: 0.9540\n",
      "Epoch 66/75\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0772 - accuracy: 0.9799 - val_loss: 0.2635 - val_accuracy: 0.9552\n",
      "Epoch 67/75\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0773 - accuracy: 0.9796 - val_loss: 0.2593 - val_accuracy: 0.9559\n",
      "Epoch 68/75\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.0749 - accuracy: 0.9813 - val_loss: 0.2880 - val_accuracy: 0.9503\n",
      "Epoch 69/75\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.0738 - accuracy: 0.9804 - val_loss: 0.2699 - val_accuracy: 0.9565\n",
      "Epoch 70/75\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0717 - accuracy: 0.9816 - val_loss: 0.2868 - val_accuracy: 0.9448\n",
      "Epoch 71/75\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.0720 - accuracy: 0.9821 - val_loss: 0.2790 - val_accuracy: 0.9559\n",
      "Epoch 72/75\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.0709 - accuracy: 0.9822 - val_loss: 0.3280 - val_accuracy: 0.9375\n",
      "Epoch 73/75\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.9816 - val_loss: 0.2824 - val_accuracy: 0.9540\n",
      "Epoch 74/75\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.0691 - accuracy: 0.9811 - val_loss: 0.2942 - val_accuracy: 0.9546\n",
      "Epoch 75/75\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.0673 - accuracy: 0.9827 - val_loss: 0.2950 - val_accuracy: 0.9497\n"
     ]
    }
   ],
   "source": [
    "model=MLP(classes = 9, features = 257, dim = 100)\n",
    "model.fit(transxtrain,transytrain,100,75,lr=.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 0, 8, ..., 1, 1, 6])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(transx_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
