{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SVM import SVM\n",
    "from MLP import MLP\n",
    "from OnlineHD_model import OnlineHD\n",
    "from OnlineHDv1 import OnlineHDv1\n",
    "from OnlineHDv2 import OnlineHDv2\n",
    "from NeuralHDv1 import NeuralHDv1\n",
    "from NeuralHDv2 import NeuralHDv2\n",
    "from testcode import NeuralHDSpecial\n",
    "from OnlineHD_model import OnlineHD\n",
    "from BIC import NeuralHDBIC\n",
    "from flexHD import NeuralHDDev\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"../../../Data/malware-classification/\"\n",
    "with open(path+'data11.npy', 'rb') as f:\n",
    "    transxtrain=np.load(f)\n",
    "    transx_test=np.load(f)\n",
    "    transytrain=np.load(f)\n",
    "    transy_test=np.load(f)\n",
    "xtr=torch.from_numpy(transxtrain).float()\n",
    "xte=torch.from_numpy(transx_test).float()\n",
    "ytr=torch.from_numpy(transytrain).long()\n",
    "yte=torch.from_numpy(transy_test).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General notes:\n",
    "#Try outputting arrays containing accuracy for each hyperparameter setting on your report.\n",
    "#That way, you will be able to easily paste the results into the excel spreadsheet.\n",
    "\n",
    "#Tine tuning parameters one by one using a for loop is prone to local minima.\n",
    "#The order in which the parameters tuned determines which local minimum is found.\n",
    "#Try running fine tuning multiple times starting with tuning a different parameter each time.\n",
    "#For example, last time you started with learning rate, so maybe start with another such as epochs\n",
    "# or dropout rate.\n",
    "#Try using initial static hyperparameters from my code, and also separately trying initial static\n",
    "#hyperparameters from the fine-tuning you already did once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLP\n",
    "#Compare my version to best version from your analysis (they look extremely similar in accuracy,\n",
    "#around 96.) Since parameters are quite different, this is evidence of local minima.\n",
    "#Hyperparameter fine tuning method is not perfect - possibility that neither of these is the best\n",
    "#Try rerunning the fine tuning starting with mine, and also with yours. \n",
    "#See if you can find hyperparameters that give better accuracy than 96.1\n",
    "#Report: Better hyperparameters and their resulting accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8151, 257) (8151, 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9609863820390137"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=MLP(classes =9, features=257, dim = 1024)#1-24\n",
    "#training\n",
    "start=time.time()\n",
    "model.fit(transxtrain,transytrain,64,64,.003)\n",
    "end=time.time()\n",
    "training=end-start\n",
    "#inference\n",
    "start=time.time()\n",
    "yhat=model(transx_test)\n",
    "end=time.time()\n",
    "inference=end-start\n",
    "eval=[yhat[i]==transy_test[i] for i in range(len(transy_test))]\n",
    "acc=sum(eval)/len(transy_test)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperdimensional Computing Functions (OnlineHD, NeuralHD, NeuralHDSpecial exotic functions such\n",
    "# as BIC and SingleStop)\n",
    "#Note about batch size:\n",
    "#Treat batch size as a special parameter - if you run it at batch size close to 1, results will\n",
    "# be better, but it will take forever. \n",
    "# Fine tune all the other parameters with batch size 64, and only after all fine tuning is done \n",
    "# check how accuracy is if you lower batch size. This way, batch size doesn't slow down tuning\n",
    "# of the other parameters.\n",
    "\n",
    "# Make sure to try dropout=0 and regens=0 for NeuralHD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"Original\" Functions\n",
    "#OnlineHDv1 and NeuralHDv1\n",
    "#Try the same tuning strategy as MLP. In addition to the initial parameters below, consider the\n",
    "#optimal parameters you found for OnlineHD and NeuralHD with train1 function\n",
    "#Report: Better hyperparameters and their resulting accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OnlineHdv1\n",
    "model=OnlineHDv1(classes =9, features =257, dim = 2048, batch_size=64,lr=.0003)\n",
    "print(\"training\")\n",
    "start=time.time()\n",
    "model.fit(xtr,ytr,75)\n",
    "end=time.time()\n",
    "print(end-start)\n",
    "print(\"inference\")\n",
    "start=time.time()\n",
    "yhat=model(xte)\n",
    "end=time.time()\n",
    "print(end-start)\n",
    "eval=[yhat[i]==transy_test[i] for i in range(len(transy_test))]\n",
    "acc=sum(eval)/len(transy_test)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=NeuralHDv1(classes =9, features =257, dim = 2048, batch_size=64,lr=.0001)\n",
    "print(\"training\")\n",
    "start=time.time()\n",
    "model.fit(xtr,ytr,35,4,.1)\n",
    "end=time.time()\n",
    "print(end-start)\n",
    "print(\"inference\")\n",
    "start=time.time()\n",
    "yhat=model(xte)\n",
    "end=time.time()\n",
    "print(end-start)\n",
    "eval=[yhat[i]==transy_test[i] for i in range(len(transy_test))]\n",
    "acc=sum(eval)/len(transy_test)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"Improved\" Functions\n",
    "#OnlineHDv2 and NeuralHDv2\n",
    "#Try the tuning. In addition to the initial parameters below, consider the\n",
    "#optimal parameters you found for OnlineHD and NeuralHD with train3 function\n",
    "#Report: Better hyperparameters and their resulting accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=OnlineHDv2(classes =9, features =257, dim = 2048, batch_size=64,lr=.0001)\n",
    "print(\"training\")\n",
    "start=time.time()\n",
    "model.fit(xtr,ytr,75)\n",
    "end=time.time()\n",
    "print(end-start)\n",
    "print(\"inference\")\n",
    "start=time.time()\n",
    "yhat=model(xte)\n",
    "end=time.time()\n",
    "print(end-start)\n",
    "eval=[yhat[i]==transy_test[i] for i in range(len(transy_test))]\n",
    "acc=sum(eval)/len(transy_test)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n",
      "25.831881046295166\n",
      "inference\n",
      "0.043576955795288086\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9536)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=NeuralHDv2(classes =9, features =257, dim = 2048, batch_size=64,lr=.0001, multiencoder=False)\n",
    "print(\"training\")\n",
    "start=time.time()\n",
    "model.fit(xtr,ytr,35,5,.1)\n",
    "end=time.time()\n",
    "print(end-start)\n",
    "print(\"inference\")\n",
    "start=time.time()\n",
    "yhat=model(xte)\n",
    "end=time.time()\n",
    "print(end-start)\n",
    "eval=[yhat[i]==transy_test[i] for i in range(len(transy_test))]\n",
    "acc=sum(eval)/len(transy_test)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"Experimental\" Functions\n",
    "#NeuralHDSpecial BIC=True, \"SingleStop\"\n",
    "#Try the tuning. See if the same parameters that are good for NeuralHDv2 normal are also good\n",
    "#for BIC version, and figure out if optimal BIC version has better accuracy than optimal \n",
    "#Report: hyperparameters, accuracy, and is it better than NeuralHDv2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bobbymissirian/Files/Research/Cybersecurity/Experiments/testcode.py:62: UserWarning: An output with one or more elements was resized since it had shape [257, 2048], which does not match the required output shape [184, 2048].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  torch.matmul(x[i:i+bsize], self.basis.T, out=temp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.650975942611694\n",
      "inference\n",
      "0.043467044830322266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bobbymissirian/Files/Research/Cybersecurity/Experiments/testcode.py:62: UserWarning: An output with one or more elements was resized since it had shape [257, 2048], which does not match the required output shape [147, 2048].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  torch.matmul(x[i:i+bsize], self.basis.T, out=temp)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9584)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=NeuralHDSpecial(9,257,2048,batch_size=64,trainopt=2,bestinclass=True,lr=.0001)\n",
    "print(\"training\")\n",
    "start=time.time()\n",
    "model.fit(xtr,ytr,35,6,.1)\n",
    "end=time.time()\n",
    "print(end-start)\n",
    "print(\"inference\")\n",
    "start=time.time()\n",
    "yhat=model(xte)\n",
    "end=time.time()\n",
    "print(end-start)\n",
    "eval=[yhat[i]==transy_test[i] for i in range(len(transy_test))]\n",
    "acc=sum(eval)/len(transy_test)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A \"Single Stop\" is when you run model.fit normally, but when it stops, you run another model\n",
    "# of batch size 1. For some reason, this works only when you don't use have a regen in the first\n",
    "# fit.\n",
    "# Feel free to experiment with this strange effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "0.0001\n",
      "64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bobbymissirian/Files/Research/Cybersecurity/Experiments/flexHD.py:61: UserWarning: An output with one or more elements was resized since it had shape [257, 1024], which does not match the required output shape [184, 1024].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  torch.matmul(x[i:i+bsize], self.basis.T, out=temp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bobbymissirian/Files/Research/Cybersecurity/Experiments/flexHD.py:61: UserWarning: An output with one or more elements was resized since it had shape [257, 1024], which does not match the required output shape [147, 1024].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  torch.matmul(x[i:i+bsize], self.basis.T, out=temp)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9595)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=NeuralHDDev(9,257,1024,trainopt=2,bestinclass=True, multiencoder=True)\n",
    "models=model.fit(xtr,ytr,64,0,0,.0001,64,1)#Initial training\n",
    "models=model.fit(xtr,ytr,6,1,0,.0001,1,1)#Initial training\n",
    "yhat=model(xte)\n",
    "eval=[yhat[i]==transy_test[i] for i in range(len(transy_test))]\n",
    "ekans=sum(eval)/len(transy_test)\n",
    "ekans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "0.0001\n",
      "64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bobbymissirian/Files/Research/Cybersecurity/Experiments/flexHD.py:61: UserWarning: An output with one or more elements was resized since it had shape [257, 2048], which does not match the required output shape [184, 2048].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  torch.matmul(x[i:i+bsize], self.basis.T, out=temp)\n",
      "/Users/bobbymissirian/Files/Research/Cybersecurity/Experiments/flexHD.py:61: UserWarning: An output with one or more elements was resized since it had shape [257, 2048], which does not match the required output shape [147, 2048].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  torch.matmul(x[i:i+bsize], self.basis.T, out=temp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "0.0001\n",
      "64\n",
      "test\n",
      "0.0001\n",
      "64\n",
      "test\n",
      "0.0001\n",
      "64\n",
      "test\n",
      "0.0001\n",
      "64\n",
      "test\n",
      "0.0001\n",
      "64\n",
      "test\n",
      "0.0001\n",
      "64\n",
      "test\n",
      "0.0001\n",
      "64\n",
      "test\n",
      "0.0001\n",
      "64\n",
      "test\n",
      "0.0001\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "accs=[]\n",
    "for i in range(10):\n",
    "    model=NeuralHDDev(9,257,2048,trainopt=2,bestinclass=True, multiencoder=True)\n",
    "    model.basis=torch.load(\"StitchHD/basis.pt\")\n",
    "    models=model.fit(xtr[:int(1*len(xtr))],ytr[:int(1*len(xtr))],64,30,0,.0001,64,1)#Initial training\n",
    "    yhat=model(xte)\n",
    "    eval=[yhat[i]==transy_test[i] for i in range(len(transy_test))]\n",
    "    ekans=sum(eval)/len(transy_test)\n",
    "    accs.append(ekans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.9687),\n",
       " tensor(0.9672),\n",
       " tensor(0.9706),\n",
       " tensor(0.9706),\n",
       " tensor(0.9698),\n",
       " tensor(0.9695),\n",
       " tensor(0.9739),\n",
       " tensor(0.9695),\n",
       " tensor(0.9709),\n",
       " tensor(0.9698)]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96981966"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bobbymissirian/Files/Research/Cybersecurity/Experiments/flexHD.py:61: UserWarning: An output with one or more elements was resized since it had shape [257, 2048], which does not match the required output shape [147, 2048].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  torch.matmul(x[i:i+bsize], self.basis.T, out=temp)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9687)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "copies=[88,89,90,91,92,93,94,95,96,97,98,99,100]\n",
    "beforeaccs=[]\n",
    "start=time.time()\n",
    "model=NeuralHDDev(9,257,2048,trainopt=2,bestinclass=True, multiencoder=True)\n",
    "models=model.fit(xtr,ytr,50,1,0,.0001,1,1,copies)#Initial training\n",
    "afteraccs=[]\n",
    "for model in models:\n",
    "    yhat=model(xtr)\n",
    "    eval=[yhat[i]==transytrain[i] for i in range(len(transytrain))]\n",
    "    beforeaccs.append(sum(eval)/len(transytrain))\n",
    "    model.fit(xtr,ytr,6,1,0,.0001,1,1)\n",
    "    yhat=model(xte)\n",
    "    eval=[yhat[i]==transy_test[i] for i in range(len(transy_test))]\n",
    "    afteraccs.append(sum(eval)/len(transy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.9872),\n",
       " tensor(0.9875),\n",
       " tensor(0.9863),\n",
       " tensor(0.9817),\n",
       " tensor(0.9870),\n",
       " tensor(0.9864),\n",
       " tensor(0.9859),\n",
       " tensor(0.9861),\n",
       " tensor(0.9837),\n",
       " tensor(0.9836),\n",
       " tensor(0.9871),\n",
       " tensor(0.9854),\n",
       " tensor(0.9863)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beforeaccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.9617),\n",
       " tensor(0.9643),\n",
       " tensor(0.9639),\n",
       " tensor(0.9639),\n",
       " tensor(0.9636),\n",
       " tensor(0.9636),\n",
       " tensor(0.9628),\n",
       " tensor(0.9632),\n",
       " tensor(0.9639),\n",
       " tensor(0.9628),\n",
       " tensor(0.9639),\n",
       " tensor(0.9647),\n",
       " tensor(0.9632)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afteraccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.9628),\n",
       " tensor(0.9603),\n",
       " tensor(0.9610),\n",
       " tensor(0.9643),\n",
       " tensor(0.9639),\n",
       " tensor(0.9621),\n",
       " tensor(0.9610),\n",
       " tensor(0.9625),\n",
       " tensor(0.9628),\n",
       " tensor(0.9588),\n",
       " tensor(0.9636),\n",
       " tensor(0.9603),\n",
       " tensor(0.9625)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "0.0001\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bobbymissirian/Files/Research/Cybersecurity/Experiments/flexHD.py:61: UserWarning: An output with one or more elements was resized since it had shape [257, 2048], which does not match the required output shape [184, 2048].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  torch.matmul(x[i:i+bsize], self.basis.T, out=temp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bobbymissirian/Files/Research/Cybersecurity/Experiments/flexHD.py:61: UserWarning: An output with one or more elements was resized since it had shape [257, 2048], which does not match the required output shape [147, 2048].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  torch.matmul(x[i:i+bsize], self.basis.T, out=temp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n",
      "0.0001\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "copies=[38,39,40,41,42,43,44,45,46,47,48,49,50]\n",
    "start=time.time()\n",
    "model=NeuralHDDev(9,257,2048,trainopt=2,bestinclass=True, multiencoder=True)\n",
    "models=model.fit(xtr,ytr,50,0,0,.0001,1,1,copies)#Initial training\n",
    "accs=[]\n",
    "for model in models:\n",
    "    model.fit(xtr,ytr,6,1,0,.0001,1,1)\n",
    "    yhat=model(xte)\n",
    "    eval=[yhat[i]==transy_test[i] for i in range(len(transy_test))]\n",
    "    accs.append(sum(eval)/len(transy_test))\n",
    "# model.fit(xtr,ytr,6,1,0,.0001,1,1)# stop training\n",
    "# end=time.time()\n",
    "# print(end-start)\n",
    "# print(\"inference\")\n",
    "# start=time.time()\n",
    "# yhat=model(xte)\n",
    "# end=time.time()\n",
    "# print(end-start)\n",
    "# eval=[yhat[i]==transy_test[i] for i in range(len(transy_test))]\n",
    "# acc=sum(eval)/len(transy_test)\n",
    "# print(acc)\n",
    "# model.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.9614),\n",
       " tensor(0.9614),\n",
       " tensor(0.9599),\n",
       " tensor(0.9588),\n",
       " tensor(0.9569),\n",
       " tensor(0.9591),\n",
       " tensor(0.9614),\n",
       " tensor(0.9588),\n",
       " tensor(0.9588),\n",
       " tensor(0.9639),\n",
       " tensor(0.9599),\n",
       " tensor(0.9610),\n",
       " tensor(0.9573)]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.9625),\n",
       " tensor(0.9625),\n",
       " tensor(0.9603),\n",
       " tensor(0.9588),\n",
       " tensor(0.9595),\n",
       " tensor(0.9617),\n",
       " tensor(0.9595)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bobbymissirian/Files/Research/Cybersecurity/Experiments/flexHD.py:61: UserWarning: An output with one or more elements was resized since it had shape [257, 2048], which does not match the required output shape [133, 2048].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  torch.matmul(x[i:i+bsize], self.basis.T, out=temp)\n",
      "/Users/bobbymissirian/Files/Research/Cybersecurity/Experiments/flexHD.py:61: UserWarning: An output with one or more elements was resized since it had shape [257, 2048], which does not match the required output shape [16, 2048].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  torch.matmul(x[i:i+bsize], self.basis.T, out=temp)\n",
      "/Users/bobbymissirian/Files/Research/Cybersecurity/Experiments/flexHD.py:61: UserWarning: An output with one or more elements was resized since it had shape [257, 2048], which does not match the required output shape [155, 2048].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  torch.matmul(x[i:i+bsize], self.basis.T, out=temp)\n",
      "/Users/bobbymissirian/Files/Research/Cybersecurity/Experiments/flexHD.py:61: UserWarning: An output with one or more elements was resized since it had shape [257, 2048], which does not match the required output shape [102, 2048].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  torch.matmul(x[i:i+bsize], self.basis.T, out=temp)\n",
      "/Users/bobbymissirian/Files/Research/Cybersecurity/Experiments/flexHD.py:61: UserWarning: An output with one or more elements was resized since it had shape [257, 2048], which does not match the required output shape [32, 2048].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  torch.matmul(x[i:i+bsize], self.basis.T, out=temp)\n",
      "/Users/bobbymissirian/Files/Research/Cybersecurity/Experiments/flexHD.py:61: UserWarning: An output with one or more elements was resized since it had shape [257, 2048], which does not match the required output shape [49, 2048].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  torch.matmul(x[i:i+bsize], self.basis.T, out=temp)\n",
      "/Users/bobbymissirian/Files/Research/Cybersecurity/Experiments/flexHD.py:61: UserWarning: An output with one or more elements was resized since it had shape [257, 2048], which does not match the required output shape [46, 2048].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  torch.matmul(x[i:i+bsize], self.basis.T, out=temp)\n",
      "/Users/bobbymissirian/Files/Research/Cybersecurity/Experiments/flexHD.py:61: UserWarning: An output with one or more elements was resized since it had shape [257, 2048], which does not match the required output shape [173, 2048].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  torch.matmul(x[i:i+bsize], self.basis.T, out=temp)\n",
      "/Users/bobbymissirian/Files/Research/Cybersecurity/Experiments/flexHD.py:61: UserWarning: An output with one or more elements was resized since it had shape [257, 2048], which does not match the required output shape [249, 2048].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:23.)\n",
      "  torch.matmul(x[i:i+bsize], self.basis.T, out=temp)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "totalclearance=torch.zeros(model.dimensionality)\n",
    "for index in range(len(model.classes)):\n",
    "    classmetrics=torch.Tensor([(model.encode(xtr[ytr==index])*class_).sum(0).tolist() for class_ in model.classes])[index]\n",
    "    clearance=classmetrics-classmetrics.mean(0).tolist()\n",
    "    totalclearance+=clearance\n",
    "order = torch.argsort(totalclearance)\n",
    "plt.plot(range(len(order)),totalclearance[order])\n",
    "plt.show()\n",
    "# for classmetric in classmetrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "# check https://scikit-learn.org/stable/modules/svm.html\n",
    "#Accuracy is suspiciously low - look for ways to use different kernels such as rbf kernel\n",
    "#look for ways to optimize hyperparametes, such as GridSearchCV\n",
    "#Make sure to read: Section 1.4.6.1.\n",
    "#Report: Methods tried and their accuracy compared with SVM.py\n",
    "#Replace: The predict function in the SVM class with any function that has higher accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.620640993118286\n",
      "inference\n",
      "2.530949115753174\n"
     ]
    }
   ],
   "source": [
    "model=SVM()\n",
    "start=time.time()\n",
    "model.fit(transxtrain,transytrain)\n",
    "end=time.time()\n",
    "print(end-start)\n",
    "print(\"inference\")\n",
    "start=time.time()\n",
    "yhat=model(transx_test)\n",
    "end=time.time()\n",
    "print(end-start)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
