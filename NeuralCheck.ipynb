{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import time\n",
    "import torch\n",
    "import sklearn.datasets\n",
    "import sklearn.preprocessing\n",
    "import sklearn.model_selection\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.datasets import FashionMNIST as FMNIST\n",
    "from torchvision.datasets import EMNIST\n",
    "import torchvision.transforms as transforms\n",
    "import tensorflow as tf\n",
    "import random as r\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam, SGD, Adagrad, Adadelta, RMSprop\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Activation, BatchNormalization\n",
    "import sklearn\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "import time\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "import joblib\n",
    "from tqdm import tqdm_notebook\n",
    "import copy\n",
    "\n",
    "import Config\n",
    "import Dataloader as DL\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import HD_basis as HDB\n",
    "import HD_encoder as HDE\n",
    "import HD_classifier as HDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets=[\n",
    "    \"KDD Cup 1999\",                            #0\n",
    "    \"Microsoft Challenge BIG 2015\"             #1\n",
    "]\n",
    "presets = {\n",
    "    \"KDD Cup 1999\": {\n",
    "        \"NeuralHD\": [300,2,3,.1],\n",
    "        \"OnlineHD\": [300,1.0,.1,30,True],\n",
    "        \"MLP\": [100,5,.001],\n",
    "        \"SVM\": [10000]\n",
    "    },\n",
    "    \"Microsoft Challenge BIG 2015\": {\n",
    "        \"NeuralHD\": [3000,6,10,.1],\n",
    "        \"OnlineHD\": [3000,1.0,.1,30,True],\n",
    "        \"MLP\": [100,30,.001],\n",
    "        \"SVM\": [None]\n",
    "    }\n",
    "}\n",
    "def normalized(x,y):\n",
    "    xtrain, x_test, ytrain, y_test = None,None,None,None\n",
    "    x, x_test, y, y_test = sklearn.model_selection.train_test_split(x, y, shuffle=True)\n",
    "    scaler = sklearn.preprocessing.Normalizer().fit(x)\n",
    "    x = scaler.transform(x)\n",
    "    x_test = scaler.transform(x_test)\n",
    "\n",
    "    # changes data to pytorch's tensors\n",
    "    x = torch.from_numpy(x).float()\n",
    "    y = torch.from_numpy(y).long()\n",
    "    x_test = torch.from_numpy(x_test).float()\n",
    "    y_test = torch.from_numpy(y_test).long()\n",
    "    return x.numpy(), x_test.numpy(), y.numpy(), y_test.numpy(), scaler\n",
    "def getuniquevalues(columnname,df):\n",
    "    values={}\n",
    "    i=0\n",
    "    for entry in df[columnname]:\n",
    "        if entry not in values:\n",
    "            values[entry]=i\n",
    "            i+=1\n",
    "    return values\n",
    "def get_dataset(name):\n",
    "    if name==datasets[0]:\n",
    "        path=\"../../Data/\"\n",
    "        attacks_types = {\n",
    "            'normal': 'normal','back': 'dos','buffer_overflow': 'u2r','ftp_write': 'r2l','guess_passwd': 'r2l',\n",
    "        'imap': 'r2l','ipsweep': 'probe','land': 'dos','loadmodule': 'u2r','multihop': 'r2l','neptune': 'dos',\n",
    "        'nmap': 'probe','perl': 'u2r','phf': 'r2l','pod': 'dos','portsweep': 'probe','rootkit': 'u2r','satan': 'probe',\n",
    "        'smurf': 'dos','spy': 'r2l','teardrop': 'dos','warezclient': 'r2l','warezmaster': 'r2l',\n",
    "        }\n",
    "        cols =\"\"\"duration,protocol_type,service,flag,src_bytes,dst_bytes,land,wrong_fragment,\n",
    "        urgent,hot,num_failed_logins,logged_in,num_compromised,root_shell,su_attempted,num_root,\n",
    "        num_file_creations,num_shells,num_access_files,num_outbound_cmds,is_host_login,is_guest_login,\n",
    "        count,srv_count,serror_rate,srv_serror_rate,rerror_rate,srv_rerror_rate,same_srv_rate,\n",
    "        diff_srv_rate,srv_diff_host_rate,dst_host_count,dst_host_srv_count,dst_host_same_srv_rate,\n",
    "        dst_host_diff_srv_rate,dst_host_same_src_port_rate,dst_host_srv_diff_host_rate,\n",
    "        dst_host_serror_rate,dst_host_srv_serror_rate,dst_host_rerror_rate,dst_host_srv_rerror_rate\"\"\"\n",
    "        \n",
    "        columns =[]\n",
    "        for c in cols.split(','):\n",
    "            if(c.strip()):\n",
    "                columns.append(c.strip())\n",
    "        print(len(columns))\n",
    "        columns.append('target')\n",
    "        print(len(columns))\n",
    "\n",
    "        attack_categories=[\"dos\",\"u2r\",\"r2l\",'probe','normal']\n",
    "        df = pd.read_csv(path+\"kddcup.data_10_percent.gz\", names = columns)\n",
    "        df['Attack Type'] = df.target.apply(lambda r:attacks_types[r[:-1]])\n",
    "        del df['target']\n",
    "        df.head()\n",
    "        num_cols = df._get_numeric_data().columns\n",
    "        \n",
    "        cate_cols = list(set(df.columns)-set(num_cols))\n",
    "        cate_cols.remove('Attack Type')\n",
    "        for col in cate_cols:\n",
    "            df[col]=df[col].map(getuniquevalues(col,df))\n",
    "        data=df.to_numpy()\n",
    "        Y=df['Attack Type'].map(getuniquevalues('Attack Type',df))\n",
    "        Y=Y.to_numpy()\n",
    "        X=data[:,:-1]\n",
    "        print(Y.shape)\n",
    "        print(X.shape)\n",
    "        print(getuniquevalues('Attack Type',df))\n",
    "        xtrain, x_test, ytrain, y_test,scaler= normalized(X,Y)\n",
    "    if name==datasets[1]:\n",
    "        path=\"../../Data/malware-classification/\"\n",
    "        map={}\n",
    "        mapping=pd.read_csv(path + \"trainLabels.csv\")\n",
    "        Y=mapping[\"Class\"].to_numpy()\n",
    "        for i in range(0,len(Y)):\n",
    "            map[mapping[\"Id\"][i]]=mapping[\"Class\"][i]-1\n",
    "        byte_features=pd.read_csv(path+\"result.csv\")\n",
    "        byte_features['ID']  = byte_features['ID'].str.split('.').str[0]\n",
    "        byte_features.head(3)\n",
    "        byte_features['ID']=byte_features['ID'].map(map)\n",
    "        data=byte_features.to_numpy()\n",
    "        X=data[:,1:]\n",
    "        Y=data[:,0]\n",
    "        xtrain, x_test, ytrain, y_test,scaler= normalized(X,Y)\n",
    "    return xtrain,x_test,ytrain,y_test\n",
    "\n",
    "datasetname=\"Microsoft Challenge BIG 2015\"\n",
    "\n",
    "xtrain,x_test,ytrain,y_test=get_dataset(datasetname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralHD:\n",
    "    def __init__(self, classes : int, features : int, dim : int = 400):\n",
    "        #Configure for hdb, hdc, and hde classes\n",
    "        self.param=Config.config\n",
    "        self.param['nClasses'] = classes\n",
    "        self.param['nFeatures']= features\n",
    "        #hypervector size\n",
    "        self.param['D']=dim\n",
    "        #encoder\n",
    "        self.hde=None\n",
    "        #classifier\n",
    "        self.hdc=None\n",
    "    def __call__(self, x : torch.Tensor):\n",
    "        #True iff the model has been trained\n",
    "        assert self.hde!=None and self.hdc!=None\n",
    "        #return predicted values\n",
    "        return self.predict(x)\n",
    "    def predict(self,x):\n",
    "        #Get hypervectors for all data points\n",
    "        trainencoded=self.hde.encodeData(x)\n",
    "        #return predictions based on similarity to classification hypervectors\n",
    "        return np.array(self.hdc.predict(trainencoded))\n",
    "    def fit(self,traindata, trainlabels,valdata, vallabels,\n",
    "                   epochs,\n",
    "                   regenloops,  # list of effective dimensions to reach \n",
    "                   percentDrop # drop/regen rate \n",
    "                    ):\n",
    "        \n",
    "        # Initialize basis & classifier\n",
    "        hdb = HDB.HD_basis(HDB.Generator.Vanilla, self.param)\n",
    "        # store generated basis\n",
    "        basis = hdb.getBasis()\n",
    "        # updata params after basis generation\n",
    "        self.param = hdb.getParam()\n",
    "        # make encoder based on basis\n",
    "        self.hde = HDE.HD_encoder(basis)\n",
    "        # find encoded training vectors\n",
    "        trainencoded = self.hde.encodeData(traindata)\n",
    "        # print(valdata)\n",
    "        valencoded = self.hde.encodeData(valdata)\n",
    "        # Initialize classification hypervectors\n",
    "        self.hdc = HDC.HD_classifier(self.param[\"D\"], self.param[\"nClasses\"], 0)\n",
    "\n",
    "        # calculate amount of dropped dimensions based on percent and original dimension\n",
    "        amountDrop = int(percentDrop * self.hdc.D)#self.param.D?\n",
    "        # print(\"Updating times:\", regenloops)\n",
    "\n",
    "        for i in range(regenloops+1): # For each eDs to reach, will checkpoints\n",
    "            # print(\"regenloop: \" + str(i))\n",
    "            # train for x epochs\n",
    "            perfect=self.trainreploop(epochs,trainencoded,trainlabels, valencoded,vallabels)\n",
    "            #if its the last regeneration training, stop before doing another dimension drop; stop if 100% accuracy\n",
    "            if i==regenloops or perfect:\n",
    "                return #self.hdc,self.hde - unnecessary now that hdc and hde are within a class\n",
    "            # print(\"regeneration\")\n",
    "            #do the dimension drop and regeneration\n",
    "            trainencoded=self.regen(hdb,amountDrop,traindata)\n",
    "        return \"error\",\"error\"\n",
    "    \n",
    "    def trainreploop(self,epochs,trainencoded,trainlabels, valencoded, vallabels):\n",
    "        # Do the train \n",
    "        for j in range(epochs):\n",
    "            # do one pass of training\n",
    "            train_acc = 100 * self.hdc.fit(trainencoded, trainlabels, self.param)\n",
    "            # print(self.hdc.D)\n",
    "            # print(valencoded)\n",
    "            val_acc = 100 * self.hdc.test(valencoded, vallabels)\n",
    "            #Test accuracy used to be in here but I took it out because we dont usually know it\n",
    "            print(\"Train: %.2f \\t \\t Test: %.2f\"%(train_acc,val_acc))\n",
    "            # If accuracy is 100, finish\n",
    "            if train_acc == 100:\n",
    "                return True\n",
    "        return False\n",
    "    def regen(self,hdb,amountDrop,traindata):\n",
    "        #make order of dimensions according to variaince; also store variances <-- unnecessary?\n",
    "        var, orders = self.hdc.evaluateBasis()\n",
    "        #drop dimensions with lowest variance\n",
    "        toDrop = orders[:amountDrop]\n",
    "        # print(\"Variances stats: max %.2f, min %.2f, mean %.2f\"%(max(var),min(var),np.mean(var)))\n",
    "        #update basis by randomizing dimension\n",
    "        hdb.updateBasis(toDrop)\n",
    "        # move the new basis into the encoder\n",
    "        self.hde.updateBasis(hdb.basis)\n",
    "        # normalize previous classes so retrain has enough effect\n",
    "        self.hdc.updateClasses()\n",
    "        # get new encoded training data\n",
    "        return self.hde.encodeData(traindata)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=NeuralHD(9,xtrain.shape[1],3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating times: 5\n",
      "Updating basis......\n",
      "Updating basis......\n",
      "Updating basis......\n",
      "Updating basis......\n",
      "Updating basis......\n"
     ]
    }
   ],
   "source": [
    "model.fit(xtrain,ytrain,30,5,.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_accuracy_breakdown(model,x_test,y_test, output=False):\n",
    "    acc=[]\n",
    "    points=[]\n",
    "    try:\n",
    "        for i in range (0,len(np.unique(y_test))):\n",
    "            yhat= model.predict(x_test[y_test==i])\n",
    "            if len(yhat.shape)==2:\n",
    "                yhat=np.array([row.argmax() for row in yhat])\n",
    "            acc.append((yhat==i).mean())\n",
    "            points.append(len(yhat))\n",
    "    except:\n",
    "        for i in range (0,len(np.unique(y_test))):\n",
    "            yhat= model.predict(torch.from_numpy(x_test[y_test==i]))\n",
    "            acc.append((yhat==i).float().mean())\n",
    "            points.append(len(yhat))\n",
    "    # print(yhat[:30])\n",
    "    totacc=sum([acc[i]*points[i] for i in range(0,len(acc))])/sum(points)\n",
    "    if output:\n",
    "        plt.bar(range(0,len(acc)),acc,color=np.random.rand(3,))\n",
    "        plt.title(\"Accuracy Total: \" + str(totacc))\n",
    "        plt.show()\n",
    "    return totacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 66.69 \t \t Test: 74.98\n",
      "Train: 74.67 \t \t Test: 84.71\n",
      "Train: 77.81 \t \t Test: 64.12\n",
      "Train: 79.14 \t \t Test: 85.75\n",
      "Train: 80.73 \t \t Test: 86.01\n",
      "Updating basis......\n",
      "Train: 74.90 \t \t Test: 51.35\n",
      "Train: 78.60 \t \t Test: 70.98\n",
      "Train: 81.34 \t \t Test: 86.88\n",
      "Train: 82.04 \t \t Test: 66.12\n",
      "Train: 83.33 \t \t Test: 48.48\n",
      "Updating basis......\n",
      "Train: 76.09 \t \t Test: 84.62\n",
      "Train: 78.04 \t \t Test: 82.54\n",
      "Train: 81.30 \t \t Test: 85.84\n",
      "Train: 82.79 \t \t Test: 81.06\n",
      "Train: 82.56 \t \t Test: 85.58\n",
      "Updating basis......\n",
      "Train: 75.39 \t \t Test: 76.89\n",
      "Train: 79.41 \t \t Test: 82.62\n",
      "Train: 81.46 \t \t Test: 79.67\n",
      "Train: 83.69 \t \t Test: 53.61\n",
      "Train: 83.40 \t \t Test: 84.19\n",
      "Updating basis......\n",
      "Train: 77.24 \t \t Test: 66.12\n",
      "Train: 80.23 \t \t Test: 87.14\n",
      "Train: 81.06 \t \t Test: 64.99\n",
      "Train: 82.63 \t \t Test: 86.71\n",
      "Train: 85.13 \t \t Test: 89.75\n",
      "Updating basis......\n",
      "Train: 76.44 \t \t Test: 80.89\n",
      "Train: 80.33 \t \t Test: 48.57\n",
      "Train: 82.39 \t \t Test: 66.90\n",
      "Train: 83.50 \t \t Test: 82.62\n",
      "Train: 84.97 \t \t Test: 50.91\n",
      "Train: 66.46 \t \t Test: 59.69\n",
      "Train: 74.73 \t \t Test: 84.88\n",
      "Train: 77.44 \t \t Test: 88.36\n",
      "Train: 79.01 \t \t Test: 61.86\n",
      "Train: 80.80 \t \t Test: 86.53\n",
      "Updating basis......\n",
      "Train: 74.99 \t \t Test: 88.62\n",
      "Train: 79.43 \t \t Test: 88.18\n",
      "Train: 80.57 \t \t Test: 88.79\n",
      "Train: 80.96 \t \t Test: 90.70\n",
      "Train: 82.36 \t \t Test: 84.19\n",
      "Updating basis......\n",
      "Train: 75.23 \t \t Test: 90.27\n",
      "Train: 79.99 \t \t Test: 84.36\n",
      "Train: 80.64 \t \t Test: 86.71\n",
      "Train: 82.94 \t \t Test: 78.89\n",
      "Train: 83.83 \t \t Test: 90.88\n",
      "Updating basis......\n",
      "Train: 75.89 \t \t Test: 86.01\n",
      "Train: 80.89 \t \t Test: 60.73\n",
      "Train: 81.31 \t \t Test: 59.08\n",
      "Train: 82.99 \t \t Test: 88.01\n",
      "Train: 82.97 \t \t Test: 85.84\n",
      "Updating basis......\n",
      "Train: 76.21 \t \t Test: 48.74\n",
      "Train: 79.11 \t \t Test: 83.49\n",
      "Train: 82.84 \t \t Test: 53.61\n",
      "Train: 83.89 \t \t Test: 62.73\n",
      "Train: 84.79 \t \t Test: 55.78\n",
      "Updating basis......\n",
      "Train: 76.96 \t \t Test: 55.17\n",
      "Train: 80.00 \t \t Test: 65.77\n",
      "Train: 82.64 \t \t Test: 54.30\n",
      "Train: 83.86 \t \t Test: 34.14\n",
      "Train: 85.04 \t \t Test: 73.24\n",
      "Train: 66.16 \t \t Test: 81.15\n",
      "Train: 74.31 \t \t Test: 78.71\n",
      "Train: 77.57 \t \t Test: 55.86\n",
      "Train: 78.67 \t \t Test: 86.45\n",
      "Train: 80.99 \t \t Test: 79.06\n",
      "Updating basis......\n",
      "Train: 75.47 \t \t Test: 85.06\n",
      "Train: 78.10 \t \t Test: 50.74\n",
      "Train: 80.21 \t \t Test: 67.94\n",
      "Train: 81.37 \t \t Test: 92.27\n",
      "Train: 83.41 \t \t Test: 46.74\n",
      "Updating basis......\n",
      "Train: 75.09 \t \t Test: 51.00\n",
      "Train: 78.64 \t \t Test: 84.54\n",
      "Train: 81.09 \t \t Test: 63.25\n",
      "Train: 82.76 \t \t Test: 79.93\n",
      "Train: 83.27 \t \t Test: 64.38\n",
      "Updating basis......\n",
      "Train: 75.64 \t \t Test: 79.15\n",
      "Train: 79.19 \t \t Test: 77.32\n",
      "Train: 80.71 \t \t Test: 87.40\n",
      "Train: 84.04 \t \t Test: 91.05\n",
      "Train: 84.04 \t \t Test: 51.61\n",
      "Updating basis......\n",
      "Train: 75.73 \t \t Test: 58.47\n",
      "Train: 78.50 \t \t Test: 75.24\n",
      "Train: 81.74 \t \t Test: 60.64\n",
      "Train: 82.01 \t \t Test: 84.71\n",
      "Train: 84.33 \t \t Test: 90.44\n",
      "Updating basis......\n",
      "Train: 77.94 \t \t Test: 86.01\n",
      "Train: 79.36 \t \t Test: 82.45\n",
      "Train: 80.69 \t \t Test: 65.94\n",
      "Train: 83.20 \t \t Test: 60.30\n",
      "Train: 83.57 \t \t Test: 73.24\n",
      "Train: 66.59 \t \t Test: 82.80\n",
      "Train: 74.76 \t \t Test: 64.03\n",
      "Train: 77.83 \t \t Test: 83.58\n",
      "Train: 78.60 \t \t Test: 85.75\n",
      "Train: 80.37 \t \t Test: 61.08\n",
      "Updating basis......\n",
      "Train: 75.00 \t \t Test: 50.39\n",
      "Train: 78.51 \t \t Test: 88.18\n",
      "Train: 79.53 \t \t Test: 85.14\n",
      "Train: 82.04 \t \t Test: 80.19\n",
      "Train: 82.61 \t \t Test: 86.27\n",
      "Updating basis......\n",
      "Train: 74.77 \t \t Test: 86.45\n",
      "Train: 79.93 \t \t Test: 87.66\n",
      "Train: 82.80 \t \t Test: 93.14\n",
      "Train: 82.70 \t \t Test: 88.71\n",
      "Train: 83.56 \t \t Test: 88.27\n",
      "Updating basis......\n",
      "Train: 75.54 \t \t Test: 81.41\n",
      "Train: 78.99 \t \t Test: 64.47\n",
      "Train: 82.23 \t \t Test: 87.05\n",
      "Train: 83.17 \t \t Test: 84.19\n",
      "Train: 84.29 \t \t Test: 87.14\n",
      "Updating basis......\n",
      "Train: 76.63 \t \t Test: 64.90\n",
      "Train: 79.71 \t \t Test: 78.19\n",
      "Train: 80.84 \t \t Test: 42.57\n",
      "Train: 83.13 \t \t Test: 75.93\n",
      "Train: 83.41 \t \t Test: 42.66\n",
      "Updating basis......\n",
      "Train: 75.76 \t \t Test: 74.28\n",
      "Train: 80.16 \t \t Test: 82.02\n",
      "Train: 83.03 \t \t Test: 51.43\n",
      "Train: 84.00 \t \t Test: 47.09\n",
      "Train: 84.91 \t \t Test: 63.86\n",
      "Train: 66.87 \t \t Test: 60.99\n",
      "Train: 74.70 \t \t Test: 79.67\n",
      "Train: 76.87 \t \t Test: 55.95\n",
      "Train: 79.67 \t \t Test: 85.58\n",
      "Train: 81.21 \t \t Test: 88.18\n",
      "Updating basis......\n",
      "Train: 74.90 \t \t Test: 82.45\n",
      "Train: 78.01 \t \t Test: 89.49\n",
      "Train: 79.79 \t \t Test: 86.10\n",
      "Train: 82.31 \t \t Test: 90.96\n",
      "Train: 83.00 \t \t Test: 88.53\n",
      "Updating basis......\n",
      "Train: 75.84 \t \t Test: 80.02\n",
      "Train: 78.96 \t \t Test: 58.56\n",
      "Train: 80.51 \t \t Test: 67.68\n",
      "Train: 82.84 \t \t Test: 88.79\n",
      "Train: 83.79 \t \t Test: 62.38\n",
      "Updating basis......\n",
      "Train: 75.11 \t \t Test: 84.27\n",
      "Train: 80.27 \t \t Test: 59.69\n",
      "Train: 81.74 \t \t Test: 46.66\n",
      "Train: 81.91 \t \t Test: 77.58\n",
      "Train: 84.39 \t \t Test: 85.66\n",
      "Updating basis......\n",
      "Train: 76.69 \t \t Test: 52.22\n",
      "Train: 79.44 \t \t Test: 79.50\n",
      "Train: 81.66 \t \t Test: 87.66\n",
      "Train: 83.91 \t \t Test: 79.58\n",
      "Train: 84.53 \t \t Test: 80.54\n",
      "Updating basis......\n",
      "Train: 78.17 \t \t Test: 40.83\n",
      "Train: 79.86 \t \t Test: 76.89\n",
      "Train: 82.31 \t \t Test: 87.66\n",
      "Train: 83.11 \t \t Test: 72.11\n",
      "Train: 84.69 \t \t Test: 86.45\n",
      "Train: 66.60 \t \t Test: 80.89\n",
      "Train: 75.11 \t \t Test: 82.62\n",
      "Train: 78.09 \t \t Test: 78.37\n",
      "Train: 78.73 \t \t Test: 86.45\n",
      "Train: 79.57 \t \t Test: 82.10\n",
      "Updating basis......\n",
      "Train: 75.67 \t \t Test: 75.76\n",
      "Train: 78.79 \t \t Test: 59.86\n",
      "Train: 79.54 \t \t Test: 87.58\n",
      "Train: 81.06 \t \t Test: 82.28\n",
      "Train: 82.56 \t \t Test: 84.62\n",
      "Updating basis......\n",
      "Train: 75.49 \t \t Test: 85.58\n",
      "Train: 78.71 \t \t Test: 86.36\n",
      "Train: 80.96 \t \t Test: 81.06\n",
      "Train: 82.91 \t \t Test: 76.63\n",
      "Train: 82.80 \t \t Test: 82.28\n",
      "Updating basis......\n",
      "Train: 77.66 \t \t Test: 86.88\n",
      "Train: 80.07 \t \t Test: 79.06\n",
      "Train: 81.66 \t \t Test: 79.06\n",
      "Train: 81.33 \t \t Test: 79.41\n",
      "Train: 82.51 \t \t Test: 84.36\n",
      "Updating basis......\n",
      "Train: 76.50 \t \t Test: 84.27\n",
      "Train: 79.40 \t \t Test: 74.37\n",
      "Train: 82.17 \t \t Test: 81.67\n",
      "Train: 83.19 \t \t Test: 78.28\n",
      "Train: 83.26 \t \t Test: 82.19\n",
      "Updating basis......\n",
      "Train: 75.71 \t \t Test: 69.50\n",
      "Train: 80.47 \t \t Test: 83.32\n",
      "Train: 82.31 \t \t Test: 71.94\n",
      "Train: 83.46 \t \t Test: 83.15\n",
      "Train: 84.81 \t \t Test: 83.06\n",
      "Train: 67.20 \t \t Test: 82.71\n",
      "Train: 74.33 \t \t Test: 60.64\n",
      "Train: 76.66 \t \t Test: 86.10\n",
      "Train: 79.26 \t \t Test: 78.71\n",
      "Train: 80.40 \t \t Test: 84.54\n",
      "Updating basis......\n",
      "Train: 76.13 \t \t Test: 84.36\n",
      "Train: 78.23 \t \t Test: 83.23\n",
      "Train: 79.44 \t \t Test: 85.40\n",
      "Train: 80.43 \t \t Test: 85.75\n",
      "Train: 81.71 \t \t Test: 75.67\n",
      "Updating basis......\n",
      "Train: 76.40 \t \t Test: 74.89\n",
      "Train: 80.43 \t \t Test: 59.86\n",
      "Train: 81.01 \t \t Test: 56.91\n",
      "Train: 82.67 \t \t Test: 65.25\n",
      "Train: 83.57 \t \t Test: 78.28\n",
      "Updating basis......\n",
      "Train: 76.80 \t \t Test: 77.85\n",
      "Train: 79.60 \t \t Test: 79.32\n",
      "Train: 81.99 \t \t Test: 63.34\n",
      "Train: 82.46 \t \t Test: 91.83\n",
      "Train: 83.77 \t \t Test: 57.52\n",
      "Updating basis......\n",
      "Train: 77.01 \t \t Test: 72.37\n",
      "Train: 79.41 \t \t Test: 81.58\n",
      "Train: 81.26 \t \t Test: 86.36\n",
      "Train: 82.89 \t \t Test: 84.97\n",
      "Train: 85.04 \t \t Test: 80.19\n",
      "Updating basis......\n",
      "Train: 77.37 \t \t Test: 77.32\n",
      "Train: 81.06 \t \t Test: 83.23\n",
      "Train: 82.10 \t \t Test: 69.42\n",
      "Train: 83.31 \t \t Test: 85.58\n",
      "Train: 84.36 \t \t Test: 77.67\n",
      "Train: 66.31 \t \t Test: 56.47\n",
      "Train: 74.30 \t \t Test: 76.54\n",
      "Train: 78.64 \t \t Test: 88.88\n",
      "Train: 78.46 \t \t Test: 52.65\n",
      "Train: 80.11 \t \t Test: 75.41\n",
      "Updating basis......\n",
      "Train: 75.71 \t \t Test: 66.90\n",
      "Train: 78.59 \t \t Test: 72.55\n",
      "Train: 80.13 \t \t Test: 80.80\n",
      "Train: 81.01 \t \t Test: 86.79\n",
      "Train: 83.41 \t \t Test: 81.06\n",
      "Updating basis......\n",
      "Train: 75.93 \t \t Test: 77.85\n",
      "Train: 79.84 \t \t Test: 86.01\n",
      "Train: 81.27 \t \t Test: 50.65\n",
      "Train: 82.16 \t \t Test: 83.41\n",
      "Train: 82.59 \t \t Test: 86.79\n",
      "Updating basis......\n",
      "Train: 76.47 \t \t Test: 76.02\n",
      "Train: 79.23 \t \t Test: 86.19\n",
      "Train: 81.56 \t \t Test: 82.36\n",
      "Train: 81.93 \t \t Test: 85.06\n",
      "Train: 83.04 \t \t Test: 85.49\n",
      "Updating basis......\n",
      "Train: 76.77 \t \t Test: 71.42\n",
      "Train: 79.50 \t \t Test: 84.45\n",
      "Train: 81.03 \t \t Test: 83.67\n",
      "Train: 83.57 \t \t Test: 71.85\n",
      "Train: 83.34 \t \t Test: 58.21\n",
      "Updating basis......\n",
      "Train: 76.94 \t \t Test: 81.67\n",
      "Train: 79.27 \t \t Test: 66.64\n",
      "Train: 82.97 \t \t Test: 56.56\n",
      "Train: 84.11 \t \t Test: 58.73\n",
      "Train: 84.70 \t \t Test: 45.35\n",
      "Train: 67.09 \t \t Test: 78.19\n",
      "Train: 74.27 \t \t Test: 82.62\n",
      "Train: 77.57 \t \t Test: 77.93\n",
      "Train: 78.56 \t \t Test: 85.84\n",
      "Train: 80.94 \t \t Test: 49.61\n",
      "Updating basis......\n",
      "Train: 75.49 \t \t Test: 75.76\n",
      "Train: 79.14 \t \t Test: 76.19\n",
      "Train: 78.49 \t \t Test: 66.99\n",
      "Train: 82.20 \t \t Test: 85.66\n",
      "Train: 83.60 \t \t Test: 70.46\n",
      "Updating basis......\n",
      "Train: 74.77 \t \t Test: 80.45\n",
      "Train: 78.53 \t \t Test: 74.02\n",
      "Train: 79.64 \t \t Test: 85.58\n",
      "Train: 81.27 \t \t Test: 85.66\n",
      "Train: 82.49 \t \t Test: 62.81\n",
      "Updating basis......\n",
      "Train: 75.36 \t \t Test: 80.45\n",
      "Train: 79.46 \t \t Test: 38.66\n",
      "Train: 81.99 \t \t Test: 85.32\n",
      "Train: 83.47 \t \t Test: 76.46\n",
      "Train: 83.70 \t \t Test: 87.58\n",
      "Updating basis......\n",
      "Train: 76.76 \t \t Test: 66.64\n",
      "Train: 81.29 \t \t Test: 77.50\n",
      "Train: 82.17 \t \t Test: 39.27\n",
      "Train: 83.71 \t \t Test: 72.28\n",
      "Train: 83.87 \t \t Test: 47.26\n",
      "Updating basis......\n",
      "Train: 77.51 \t \t Test: 41.36\n",
      "Train: 80.97 \t \t Test: 49.70\n",
      "Train: 81.54 \t \t Test: 81.49\n",
      "Train: 83.50 \t \t Test: 77.32\n",
      "Train: 84.79 \t \t Test: 35.79\n",
      "Train: 66.71 \t \t Test: 47.70\n",
      "Train: 75.14 \t \t Test: 77.58\n",
      "Train: 78.01 \t \t Test: 85.40\n",
      "Train: 79.81 \t \t Test: 84.27\n",
      "Train: 80.73 \t \t Test: 85.66\n",
      "Updating basis......\n",
      "Train: 74.27 \t \t Test: 67.07\n",
      "Train: 78.77 \t \t Test: 76.89\n",
      "Train: 80.94 \t \t Test: 83.75\n",
      "Train: 81.21 \t \t Test: 88.97\n",
      "Train: 82.97 \t \t Test: 81.84\n",
      "Updating basis......\n",
      "Train: 75.10 \t \t Test: 86.36\n",
      "Train: 79.41 \t \t Test: 83.15\n",
      "Train: 81.11 \t \t Test: 89.66\n",
      "Train: 82.94 \t \t Test: 75.50\n",
      "Train: 84.29 \t \t Test: 80.80\n",
      "Updating basis......\n",
      "Train: 75.31 \t \t Test: 72.89\n",
      "Train: 80.30 \t \t Test: 76.37\n",
      "Train: 80.87 \t \t Test: 45.00\n",
      "Train: 82.14 \t \t Test: 72.20\n",
      "Train: 83.03 \t \t Test: 70.98\n",
      "Updating basis......\n",
      "Train: 76.87 \t \t Test: 81.32\n",
      "Train: 79.54 \t \t Test: 76.02\n",
      "Train: 82.36 \t \t Test: 80.89\n",
      "Train: 83.69 \t \t Test: 78.63\n",
      "Train: 83.81 \t \t Test: 84.36\n",
      "Updating basis......\n",
      "Train: 77.96 \t \t Test: 78.28\n",
      "Train: 80.94 \t \t Test: 82.10\n",
      "Train: 82.01 \t \t Test: 53.08\n",
      "Train: 83.53 \t \t Test: 57.34\n",
      "Train: 85.34 \t \t Test: 56.99\n",
      "Train: 67.13 \t \t Test: 53.87\n",
      "Train: 74.64 \t \t Test: 59.34\n",
      "Train: 76.54 \t \t Test: 84.27\n",
      "Train: 79.04 \t \t Test: 84.27\n",
      "Train: 79.96 \t \t Test: 61.08\n",
      "Updating basis......\n",
      "Train: 74.46 \t \t Test: 84.80\n",
      "Train: 78.31 \t \t Test: 76.28\n",
      "Train: 80.06 \t \t Test: 85.84\n",
      "Train: 82.11 \t \t Test: 85.49\n",
      "Train: 82.87 \t \t Test: 88.27\n",
      "Updating basis......\n",
      "Train: 75.04 \t \t Test: 53.61\n",
      "Train: 78.96 \t \t Test: 88.01\n",
      "Train: 81.43 \t \t Test: 87.40\n",
      "Train: 82.74 \t \t Test: 84.80\n",
      "Train: 83.56 \t \t Test: 81.84\n",
      "Updating basis......\n",
      "Train: 76.59 \t \t Test: 38.92\n",
      "Train: 78.47 \t \t Test: 77.85\n",
      "Train: 81.30 \t \t Test: 83.84\n",
      "Train: 82.49 \t \t Test: 90.18\n",
      "Train: 82.84 \t \t Test: 84.36\n",
      "Updating basis......\n",
      "Train: 75.67 \t \t Test: 81.32\n",
      "Train: 79.91 \t \t Test: 85.49\n",
      "Train: 82.29 \t \t Test: 56.65\n",
      "Train: 83.59 \t \t Test: 53.26\n",
      "Train: 84.46 \t \t Test: 59.60\n",
      "Updating basis......\n",
      "Train: 76.73 \t \t Test: 67.68\n",
      "Train: 78.87 \t \t Test: 79.58\n",
      "Train: 82.33 \t \t Test: 86.10\n",
      "Train: 83.77 \t \t Test: 81.67\n",
      "Train: 84.46 \t \t Test: 76.54\n",
      "Train: 67.07 \t \t Test: 52.22\n",
      "Train: 74.09 \t \t Test: 86.45\n",
      "Train: 77.50 \t \t Test: 87.14\n",
      "Train: 78.96 \t \t Test: 75.15\n",
      "Train: 80.01 \t \t Test: 91.75\n",
      "Updating basis......\n",
      "Train: 75.66 \t \t Test: 58.56\n",
      "Train: 79.29 \t \t Test: 79.41\n",
      "Train: 80.46 \t \t Test: 90.62\n",
      "Train: 81.39 \t \t Test: 87.75\n",
      "Train: 82.29 \t \t Test: 84.80\n",
      "Updating basis......\n",
      "Train: 75.26 \t \t Test: 76.28\n",
      "Train: 78.54 \t \t Test: 84.27\n",
      "Train: 80.31 \t \t Test: 64.03\n",
      "Train: 81.81 \t \t Test: 82.62\n",
      "Train: 82.69 \t \t Test: 87.32\n",
      "Updating basis......\n",
      "Train: 75.31 \t \t Test: 59.17\n",
      "Train: 80.39 \t \t Test: 82.19\n",
      "Train: 80.21 \t \t Test: 51.00\n",
      "Train: 81.43 \t \t Test: 81.58\n",
      "Train: 84.61 \t \t Test: 79.32\n",
      "Updating basis......\n",
      "Train: 76.34 \t \t Test: 81.84\n",
      "Train: 80.50 \t \t Test: 84.71\n",
      "Train: 81.81 \t \t Test: 60.38\n",
      "Train: 82.54 \t \t Test: 81.67\n",
      "Train: 83.93 \t \t Test: 78.71\n",
      "Updating basis......\n",
      "Train: 77.54 \t \t Test: 39.36\n",
      "Train: 80.63 \t \t Test: 54.91\n",
      "Train: 81.80 \t \t Test: 53.69\n",
      "Train: 82.79 \t \t Test: 55.69\n",
      "Train: 83.94 \t \t Test: 49.44\n",
      "Train: 67.36 \t \t Test: 84.97\n",
      "Train: 75.01 \t \t Test: 86.27\n",
      "Train: 77.23 \t \t Test: 77.58\n",
      "Train: 80.14 \t \t Test: 84.45\n",
      "Train: 80.47 \t \t Test: 66.64\n",
      "Updating basis......\n",
      "Train: 74.47 \t \t Test: 75.76\n",
      "Train: 78.10 \t \t Test: 80.45\n",
      "Train: 81.01 \t \t Test: 86.71\n",
      "Train: 81.77 \t \t Test: 61.95\n",
      "Train: 83.03 \t \t Test: 65.60\n",
      "Updating basis......\n",
      "Train: 75.97 \t \t Test: 82.97\n",
      "Train: 79.16 \t \t Test: 52.39\n",
      "Train: 81.50 \t \t Test: 86.45\n",
      "Train: 82.76 \t \t Test: 84.19\n",
      "Train: 83.71 \t \t Test: 83.49\n",
      "Updating basis......\n",
      "Train: 74.97 \t \t Test: 73.15\n",
      "Train: 80.23 \t \t Test: 68.64\n",
      "Train: 81.60 \t \t Test: 71.16\n",
      "Train: 83.13 \t \t Test: 88.88\n",
      "Train: 84.10 \t \t Test: 78.45\n",
      "Updating basis......\n",
      "Train: 75.73 \t \t Test: 75.93\n",
      "Train: 79.83 \t \t Test: 84.62\n",
      "Train: 81.54 \t \t Test: 52.74\n",
      "Train: 83.14 \t \t Test: 79.50\n",
      "Train: 83.57 \t \t Test: 84.45\n",
      "Updating basis......\n",
      "Train: 76.89 \t \t Test: 43.79\n",
      "Train: 80.51 \t \t Test: 56.04\n",
      "Train: 83.11 \t \t Test: 35.19\n",
      "Train: 82.30 \t \t Test: 60.99\n",
      "Train: 84.99 \t \t Test: 84.71\n",
      "Train: 66.61 \t \t Test: 78.97\n",
      "Train: 74.53 \t \t Test: 86.27\n",
      "Train: 79.01 \t \t Test: 83.41\n",
      "Train: 79.57 \t \t Test: 84.88\n",
      "Train: 79.97 \t \t Test: 86.27\n",
      "Updating basis......\n",
      "Train: 75.11 \t \t Test: 87.32\n",
      "Train: 78.99 \t \t Test: 81.06\n",
      "Train: 81.13 \t \t Test: 89.83\n",
      "Train: 81.50 \t \t Test: 78.63\n",
      "Train: 83.87 \t \t Test: 86.71\n",
      "Updating basis......\n",
      "Train: 76.09 \t \t Test: 55.34\n",
      "Train: 78.83 \t \t Test: 84.36\n",
      "Train: 81.61 \t \t Test: 83.06\n",
      "Train: 82.34 \t \t Test: 53.17\n",
      "Train: 84.14 \t \t Test: 84.88\n",
      "Updating basis......\n",
      "Train: 76.74 \t \t Test: 82.36\n",
      "Train: 79.60 \t \t Test: 83.32\n",
      "Train: 81.10 \t \t Test: 86.97\n",
      "Train: 82.47 \t \t Test: 60.99\n",
      "Train: 84.19 \t \t Test: 56.04\n",
      "Updating basis......\n",
      "Train: 76.07 \t \t Test: 78.80\n",
      "Train: 79.96 \t \t Test: 83.49\n",
      "Train: 82.30 \t \t Test: 78.89\n",
      "Train: 83.64 \t \t Test: 61.86\n",
      "Train: 83.44 \t \t Test: 61.77\n",
      "Updating basis......\n",
      "Train: 75.51 \t \t Test: 51.26\n",
      "Train: 80.41 \t \t Test: 70.98\n",
      "Train: 82.13 \t \t Test: 61.77\n",
      "Train: 83.69 \t \t Test: 54.21\n",
      "Train: 84.61 \t \t Test: 51.00\n",
      "Train: 66.20 \t \t Test: 82.45\n",
      "Train: 75.10 \t \t Test: 82.80\n",
      "Train: 77.54 \t \t Test: 84.54\n",
      "Train: 78.69 \t \t Test: 86.53\n",
      "Train: 80.90 \t \t Test: 87.40\n",
      "Updating basis......\n",
      "Train: 74.99 \t \t Test: 51.52\n",
      "Train: 78.63 \t \t Test: 80.89\n",
      "Train: 80.99 \t \t Test: 85.93\n",
      "Train: 81.56 \t \t Test: 79.67\n",
      "Train: 82.51 \t \t Test: 87.84\n",
      "Updating basis......\n",
      "Train: 75.17 \t \t Test: 90.88\n",
      "Train: 79.00 \t \t Test: 86.62\n",
      "Train: 82.01 \t \t Test: 91.83\n",
      "Train: 82.57 \t \t Test: 67.77\n",
      "Train: 83.64 \t \t Test: 52.56\n",
      "Updating basis......\n",
      "Train: 75.84 \t \t Test: 86.71\n",
      "Train: 79.26 \t \t Test: 83.93\n",
      "Train: 81.14 \t \t Test: 86.79\n",
      "Train: 82.56 \t \t Test: 76.80\n",
      "Train: 83.90 \t \t Test: 78.02\n",
      "Updating basis......\n",
      "Train: 76.76 \t \t Test: 83.75\n",
      "Train: 80.31 \t \t Test: 84.88\n",
      "Train: 82.49 \t \t Test: 86.97\n",
      "Train: 81.89 \t \t Test: 77.50\n",
      "Train: 83.63 \t \t Test: 84.19\n",
      "Updating basis......\n",
      "Train: 76.76 \t \t Test: 79.76\n",
      "Train: 80.24 \t \t Test: 76.98\n",
      "Train: 82.57 \t \t Test: 82.62\n",
      "Train: 83.19 \t \t Test: 82.19\n",
      "Train: 83.66 \t \t Test: 71.16\n",
      "Train: 66.60 \t \t Test: 70.89\n",
      "Train: 75.06 \t \t Test: 80.10\n",
      "Train: 77.37 \t \t Test: 80.02\n",
      "Train: 78.00 \t \t Test: 85.23\n",
      "Train: 80.46 \t \t Test: 89.49\n",
      "Updating basis......\n",
      "Train: 75.33 \t \t Test: 57.25\n",
      "Train: 78.97 \t \t Test: 59.17\n",
      "Train: 80.94 \t \t Test: 87.05\n",
      "Train: 81.20 \t \t Test: 88.10\n",
      "Train: 81.59 \t \t Test: 84.01\n",
      "Updating basis......\n",
      "Train: 75.60 \t \t Test: 78.89\n",
      "Train: 78.87 \t \t Test: 79.76\n",
      "Train: 81.21 \t \t Test: 82.10\n",
      "Train: 81.86 \t \t Test: 83.15\n",
      "Train: 83.73 \t \t Test: 84.45\n",
      "Updating basis......\n",
      "Train: 75.96 \t \t Test: 80.71\n",
      "Train: 78.63 \t \t Test: 59.69\n",
      "Train: 80.69 \t \t Test: 85.23\n",
      "Train: 82.10 \t \t Test: 85.49\n",
      "Train: 83.14 \t \t Test: 84.97\n",
      "Updating basis......\n",
      "Train: 76.91 \t \t Test: 76.11\n",
      "Train: 79.86 \t \t Test: 87.40\n",
      "Train: 80.67 \t \t Test: 65.86\n",
      "Train: 82.57 \t \t Test: 78.71\n",
      "Train: 83.36 \t \t Test: 66.29\n",
      "Updating basis......\n",
      "Train: 76.76 \t \t Test: 53.08\n",
      "Train: 80.17 \t \t Test: 66.03\n",
      "Train: 81.30 \t \t Test: 69.50\n",
      "Train: 83.81 \t \t Test: 78.02\n",
      "Train: 84.56 \t \t Test: 30.32\n",
      "Train: 65.87 \t \t Test: 83.49\n",
      "Train: 75.66 \t \t Test: 80.71\n",
      "Train: 77.19 \t \t Test: 90.01\n",
      "Train: 79.80 \t \t Test: 59.08\n",
      "Train: 80.49 \t \t Test: 87.75\n",
      "Updating basis......\n",
      "Train: 75.51 \t \t Test: 81.93\n",
      "Train: 78.60 \t \t Test: 81.93\n",
      "Train: 79.87 \t \t Test: 85.23\n",
      "Train: 81.21 \t \t Test: 75.50\n",
      "Train: 82.89 \t \t Test: 77.93\n",
      "Updating basis......\n",
      "Train: 75.16 \t \t Test: 74.54\n",
      "Train: 79.19 \t \t Test: 81.23\n",
      "Train: 81.76 \t \t Test: 62.38\n",
      "Train: 81.03 \t \t Test: 58.82\n",
      "Train: 83.61 \t \t Test: 86.62\n",
      "Updating basis......\n",
      "Train: 75.33 \t \t Test: 76.11\n",
      "Train: 80.00 \t \t Test: 75.93\n",
      "Train: 81.16 \t \t Test: 76.37\n",
      "Train: 82.44 \t \t Test: 79.32\n",
      "Train: 83.64 \t \t Test: 76.37\n",
      "Updating basis......\n",
      "Train: 76.27 \t \t Test: 69.24\n",
      "Train: 81.16 \t \t Test: 78.11\n",
      "Train: 81.49 \t \t Test: 74.89\n",
      "Train: 83.91 \t \t Test: 73.07\n",
      "Train: 83.43 \t \t Test: 80.80\n",
      "Updating basis......\n",
      "Train: 77.16 \t \t Test: 73.94\n",
      "Train: 80.64 \t \t Test: 82.19\n",
      "Train: 82.69 \t \t Test: 83.32\n",
      "Train: 83.69 \t \t Test: 55.34\n",
      "Train: 83.94 \t \t Test: 47.18\n",
      "Train: 67.07 \t \t Test: 80.02\n",
      "Train: 74.91 \t \t Test: 80.89\n",
      "Train: 76.76 \t \t Test: 87.58\n",
      "Train: 78.86 \t \t Test: 75.33\n",
      "Train: 80.14 \t \t Test: 62.81\n",
      "Updating basis......\n",
      "Train: 75.73 \t \t Test: 85.66\n",
      "Train: 78.60 \t \t Test: 77.06\n",
      "Train: 80.74 \t \t Test: 87.23\n",
      "Train: 81.50 \t \t Test: 86.88\n",
      "Train: 81.77 \t \t Test: 66.81\n",
      "Updating basis......\n",
      "Train: 75.24 \t \t Test: 83.23\n",
      "Train: 78.77 \t \t Test: 84.62\n",
      "Train: 81.17 \t \t Test: 84.36\n",
      "Train: 83.54 \t \t Test: 77.15\n",
      "Train: 82.80 \t \t Test: 59.08\n",
      "Updating basis......\n",
      "Train: 75.69 \t \t Test: 86.27\n",
      "Train: 78.63 \t \t Test: 52.13\n",
      "Train: 81.71 \t \t Test: 70.89\n",
      "Train: 82.67 \t \t Test: 40.57\n",
      "Train: 83.73 \t \t Test: 54.30\n",
      "Updating basis......\n",
      "Train: 76.87 \t \t Test: 80.10\n",
      "Train: 79.59 \t \t Test: 70.81\n",
      "Train: 81.33 \t \t Test: 89.57\n",
      "Train: 82.60 \t \t Test: 89.40\n",
      "Train: 84.11 \t \t Test: 85.66\n",
      "Updating basis......\n",
      "Train: 77.33 \t \t Test: 51.43\n",
      "Train: 79.60 \t \t Test: 64.81\n",
      "Train: 82.31 \t \t Test: 83.84\n",
      "Train: 83.86 \t \t Test: 82.54\n",
      "Train: 85.11 \t \t Test: 55.86\n",
      "Train: 66.31 \t \t Test: 78.80\n",
      "Train: 73.70 \t \t Test: 86.62\n",
      "Train: 77.61 \t \t Test: 82.88\n",
      "Train: 79.11 \t \t Test: 88.44\n",
      "Train: 81.13 \t \t Test: 87.49\n",
      "Updating basis......\n",
      "Train: 74.47 \t \t Test: 61.60\n",
      "Train: 77.44 \t \t Test: 84.10\n",
      "Train: 80.77 \t \t Test: 82.97\n",
      "Train: 81.64 \t \t Test: 83.75\n",
      "Train: 82.54 \t \t Test: 59.60\n",
      "Updating basis......\n",
      "Train: 75.64 \t \t Test: 90.79\n",
      "Train: 79.13 \t \t Test: 81.58\n",
      "Train: 81.67 \t \t Test: 79.41\n",
      "Train: 82.00 \t \t Test: 86.19\n",
      "Train: 83.09 \t \t Test: 80.45\n",
      "Updating basis......\n",
      "Train: 76.14 \t \t Test: 79.50\n",
      "Train: 80.51 \t \t Test: 84.97\n",
      "Train: 80.99 \t \t Test: 69.77\n",
      "Train: 82.33 \t \t Test: 79.50\n",
      "Train: 82.76 \t \t Test: 92.18\n",
      "Updating basis......\n",
      "Train: 77.20 \t \t Test: 65.94\n",
      "Train: 79.29 \t \t Test: 85.58\n",
      "Train: 81.76 \t \t Test: 86.79\n",
      "Train: 83.66 \t \t Test: 51.26\n",
      "Train: 84.30 \t \t Test: 84.62\n",
      "Updating basis......\n",
      "Train: 77.16 \t \t Test: 68.11\n",
      "Train: 80.93 \t \t Test: 67.59\n",
      "Train: 81.71 \t \t Test: 89.05\n",
      "Train: 83.60 \t \t Test: 78.54\n",
      "Train: 84.30 \t \t Test: 83.32\n",
      "Train: 66.03 \t \t Test: 76.63\n",
      "Train: 74.44 \t \t Test: 86.10\n",
      "Train: 78.13 \t \t Test: 61.60\n",
      "Train: 79.90 \t \t Test: 78.54\n",
      "Train: 79.57 \t \t Test: 72.28\n",
      "Updating basis......\n",
      "Train: 76.20 \t \t Test: 77.76\n",
      "Train: 78.56 \t \t Test: 79.15\n",
      "Train: 79.56 \t \t Test: 79.32\n",
      "Train: 81.99 \t \t Test: 79.93\n",
      "Train: 82.91 \t \t Test: 86.88\n",
      "Updating basis......\n",
      "Train: 75.09 \t \t Test: 71.42\n",
      "Train: 79.21 \t \t Test: 79.76\n",
      "Train: 81.81 \t \t Test: 76.28\n",
      "Train: 82.46 \t \t Test: 64.90\n",
      "Train: 84.47 \t \t Test: 86.10\n",
      "Updating basis......\n",
      "Train: 76.09 \t \t Test: 76.28\n",
      "Train: 79.90 \t \t Test: 74.63\n",
      "Train: 81.10 \t \t Test: 84.19\n",
      "Train: 83.80 \t \t Test: 83.93\n",
      "Train: 83.97 \t \t Test: 83.93\n",
      "Updating basis......\n",
      "Train: 75.96 \t \t Test: 72.89\n",
      "Train: 80.36 \t \t Test: 85.75\n",
      "Train: 81.80 \t \t Test: 77.41\n",
      "Train: 84.04 \t \t Test: 78.54\n",
      "Train: 84.31 \t \t Test: 75.07\n",
      "Updating basis......\n",
      "Train: 76.57 \t \t Test: 59.08\n",
      "Train: 80.77 \t \t Test: 84.36\n",
      "Train: 84.57 \t \t Test: 78.63\n",
      "Train: 84.34 \t \t Test: 67.77\n",
      "Train: 83.39 \t \t Test: 69.50\n"
     ]
    }
   ],
   "source": [
    "accuracies=[]\n",
    "for i in range(0,20):\n",
    "    model=NeuralHD(len(np.unique(y_test)),xtrain.shape[1],3000)\n",
    "    model.fit(xtrain[:7000],ytrain[:7000],xtrain[7000:],ytrain[7000:],5,5,.1)\n",
    "    accuracies.append(get_class_accuracy_breakdown(model,x_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8001472211998528, 0.9109311740890689, 0.8376886271623114, 0.8439455281560545, 0.9138755980861244, 0.8693411851306588, 0.8840633051159367, 0.860875966139124, 0.9112992270887008, 0.6481413323518587, 0.8306956201693044, 0.881854987118145, 0.9020979020979021, 0.8575634891424365, 0.8078763341921237, 0.5752668384247331, 0.8730217151269782, 0.84688995215311, 0.8689731321310269, 0.8726536621273463]\n"
     ]
    }
   ],
   "source": [
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8398601398601396\n"
     ]
    }
   ],
   "source": [
    "print(sum(accuracies)/len(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0 accuracy: 0.9074550128534704\n",
      "points: 389\n",
      "class 1 accuracy: 0.9683042789223455\n",
      "points: 631\n",
      "class 2 accuracy: 0.9090909090909091\n",
      "points: 737\n",
      "class 3 accuracy: 0.9754098360655737\n",
      "points: 122\n",
      "class 4 accuracy: 0.0\n",
      "points: 11\n",
      "class 5 accuracy: 0.7918781725888325\n",
      "points: 197\n",
      "class 6 accuracy: 0.979381443298969\n",
      "points: 97\n",
      "class 7 accuracy: 0.684887459807074\n",
      "points: 311\n",
      "class 8 accuracy: 0.918918918918919\n",
      "points: 222\n",
      "0.8910563121089436\n"
     ]
    }
   ],
   "source": [
    "accuracies=[]\n",
    "points=[]\n",
    "for i in range (0,model.param['nClasses']):\n",
    "    yhat= model(x_test[y_test==i])\n",
    "    acc = (yhat==i).mean()\n",
    "    accuracies.append(acc)\n",
    "    points.append(len(yhat))\n",
    "    print('class '+str(i)+' accuracy: ' +str(acc))\n",
    "    print('points: '+ str(len(yhat)))\n",
    "print(sum([accuracies[i]*points[i] for i in range(0,len(accuracies))])/sum(points))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
