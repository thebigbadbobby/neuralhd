{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import time\n",
    "import torch\n",
    "import sklearn.datasets\n",
    "import sklearn.preprocessing\n",
    "import sklearn.model_selection\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.datasets import FashionMNIST as FMNIST\n",
    "from torchvision.datasets import EMNIST\n",
    "import torchvision.transforms as transforms\n",
    "import tensorflow as tf\n",
    "import random as r\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam, SGD, Adagrad, Adadelta, RMSprop\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Activation, BatchNormalization\n",
    "import sklearn\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "import time\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "import joblib\n",
    "from tqdm import tqdm_notebook\n",
    "import copy\n",
    "\n",
    "import Config\n",
    "import Dataloader as DL\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets=[\n",
    "    \"KDD Cup 1999\",                            #0\n",
    "    \"Microsoft Challenge BIG 2015\"             #1\n",
    "]\n",
    "presets = {\n",
    "    \"KDD Cup 1999\": {\n",
    "        \"NeuralHD\": [300,2,3,.1],\n",
    "        \"OnlineHD\": [300,1.0,.1,30,True],\n",
    "        \"MLP\": [100,5,.001],\n",
    "        \"SVM\": [10000]\n",
    "    },\n",
    "    \"Microsoft Challenge BIG 2015\": {\n",
    "        \"NeuralHD\": [3000,6,10,.1],\n",
    "        \"OnlineHD\": [3000,1.0,.1,30,True],\n",
    "        \"MLP\": [100,30,.001],\n",
    "        \"SVM\": [None]\n",
    "    }\n",
    "}\n",
    "def normalized(x,y):\n",
    "    xtrain, x_test, ytrain, y_test = None,None,None,None\n",
    "    x, x_test, y, y_test = sklearn.model_selection.train_test_split(x, y, shuffle=True)\n",
    "    scaler = sklearn.preprocessing.Normalizer().fit(x)\n",
    "    x = scaler.transform(x)\n",
    "    x_test = scaler.transform(x_test)\n",
    "\n",
    "    # changes data to pytorch's tensors\n",
    "    x = torch.from_numpy(x).float()\n",
    "    y = torch.from_numpy(y).long()\n",
    "    x_test = torch.from_numpy(x_test).float()\n",
    "    y_test = torch.from_numpy(y_test).long()\n",
    "    return x.numpy(), x_test.numpy(), y.numpy(), y_test.numpy(), scaler\n",
    "def getuniquevalues(columnname,df):\n",
    "    values={}\n",
    "    i=0\n",
    "    for entry in df[columnname]:\n",
    "        if entry not in values:\n",
    "            values[entry]=i\n",
    "            i+=1\n",
    "    return values\n",
    "def get_dataset(name):\n",
    "    if name==datasets[0]:\n",
    "        path=\"../../Data/\"\n",
    "        attacks_types = {\n",
    "            'normal': 'normal','back': 'dos','buffer_overflow': 'u2r','ftp_write': 'r2l','guess_passwd': 'r2l',\n",
    "        'imap': 'r2l','ipsweep': 'probe','land': 'dos','loadmodule': 'u2r','multihop': 'r2l','neptune': 'dos',\n",
    "        'nmap': 'probe','perl': 'u2r','phf': 'r2l','pod': 'dos','portsweep': 'probe','rootkit': 'u2r','satan': 'probe',\n",
    "        'smurf': 'dos','spy': 'r2l','teardrop': 'dos','warezclient': 'r2l','warezmaster': 'r2l',\n",
    "        }\n",
    "        cols =\"\"\"duration,protocol_type,service,flag,src_bytes,dst_bytes,land,wrong_fragment,\n",
    "        urgent,hot,num_failed_logins,logged_in,num_compromised,root_shell,su_attempted,num_root,\n",
    "        num_file_creations,num_shells,num_access_files,num_outbound_cmds,is_host_login,is_guest_login,\n",
    "        count,srv_count,serror_rate,srv_serror_rate,rerror_rate,srv_rerror_rate,same_srv_rate,\n",
    "        diff_srv_rate,srv_diff_host_rate,dst_host_count,dst_host_srv_count,dst_host_same_srv_rate,\n",
    "        dst_host_diff_srv_rate,dst_host_same_src_port_rate,dst_host_srv_diff_host_rate,\n",
    "        dst_host_serror_rate,dst_host_srv_serror_rate,dst_host_rerror_rate,dst_host_srv_rerror_rate\"\"\"\n",
    "        \n",
    "        columns =[]\n",
    "        for c in cols.split(','):\n",
    "            if(c.strip()):\n",
    "                columns.append(c.strip())\n",
    "        print(len(columns))\n",
    "        columns.append('target')\n",
    "        print(len(columns))\n",
    "\n",
    "        attack_categories=[\"dos\",\"u2r\",\"r2l\",'probe','normal']\n",
    "        df = pd.read_csv(path+\"kddcup.data_10_percent.gz\", names = columns)\n",
    "        df['Attack Type'] = df.target.apply(lambda r:attacks_types[r[:-1]])\n",
    "        del df['target']\n",
    "        df.head()\n",
    "        num_cols = df._get_numeric_data().columns\n",
    "        \n",
    "        cate_cols = list(set(df.columns)-set(num_cols))\n",
    "        cate_cols.remove('Attack Type')\n",
    "        for col in cate_cols:\n",
    "            df[col]=df[col].map(getuniquevalues(col,df))\n",
    "        data=df.to_numpy()\n",
    "        Y=df['Attack Type'].map(getuniquevalues('Attack Type',df))\n",
    "        Y=Y.to_numpy()\n",
    "        X=data[:,:-1]\n",
    "        print(Y.shape)\n",
    "        print(X.shape)\n",
    "        print(getuniquevalues('Attack Type',df))\n",
    "        xtrain, x_test, ytrain, y_test,scaler= normalized(X,Y)\n",
    "    if name==datasets[1]:\n",
    "        path=\"../../Data/malware-classification/\"\n",
    "        map={}\n",
    "        mapping=pd.read_csv(path + \"trainLabels.csv\")\n",
    "        Y=mapping[\"Class\"].to_numpy()\n",
    "        for i in range(0,len(Y)):\n",
    "            map[mapping[\"Id\"][i]]=mapping[\"Class\"][i]-1\n",
    "        byte_features=pd.read_csv(path+\"result.csv\")\n",
    "        byte_features['ID']  = byte_features['ID'].str.split('.').str[0]\n",
    "        byte_features.head(3)\n",
    "        byte_features['ID']=byte_features['ID'].map(map)\n",
    "        data=byte_features.to_numpy()\n",
    "        X=data[:,1:]\n",
    "        Y=data[:,0]\n",
    "        xtrain, x_test, ytrain, y_test,scaler= normalized(X,Y)\n",
    "    return xtrain,x_test,ytrain,y_test\n",
    "\n",
    "datasetname=\"Microsoft Challenge BIG 2015\"\n",
    "\n",
    "xtrain,x_test,ytrain,y_test=get_dataset(datasetname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "points=[]\n",
    "for i in range (0,len(np.unique(ytrain))):\n",
    "    points.append(len(xtrain[ytrain==i]))\n",
    "plt.bar(range(0,len(points)),points, color=np.random.rand(3,))\n",
    "plt.title(\"Training Point Total: \" + str(sum(points)))\n",
    "plt.show()\n",
    "points=[]\n",
    "for i in range (0,len(np.unique(y_test))):\n",
    "    points.append(len(x_test[y_test==i]))\n",
    "plt.bar(range(0,len(points)),points, color=np.random.rand(3,))\n",
    "plt.title(\"Testing Point Total: \" + str(sum(points)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_accuracy_breakdown(model,x_test,y_test, output=False):\n",
    "    acc=[]\n",
    "    points=[]\n",
    "    try:\n",
    "        for i in range (0,len(np.unique(y_test))):\n",
    "            yhat= model.predict(x_test[y_test==i])\n",
    "            if len(yhat.shape)==2:\n",
    "                yhat=np.array([row.argmax() for row in yhat])\n",
    "            acc.append((yhat==i).mean())\n",
    "            points.append(len(yhat))\n",
    "    except:\n",
    "        for i in range (0,len(np.unique(y_test))):\n",
    "            yhat= model.predict(torch.from_numpy(x_test[y_test==i]))\n",
    "            acc.append((yhat==i).float().mean())\n",
    "            points.append(len(yhat))\n",
    "    # print(yhat[:30])\n",
    "    totacc=sum([acc[i]*points[i] for i in range(0,len(acc))])/sum(points)\n",
    "    if output:\n",
    "        plt.bar(range(0,len(acc)),acc,color=np.random.rand(3,))\n",
    "        plt.title(\"Accuracy Total: \" + str(totacc))\n",
    "        plt.show()\n",
    "    return totacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtraintorch=torch.from_numpy(xtrain)\n",
    "ytraintorch=torch.from_numpy(ytrain)\n",
    "x_testtorch=torch.from_numpy(x_test)\n",
    "y_testtorch=torch.from_numpy(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#change\n",
    "def cos_cdist(x1 : torch.Tensor, x2 : torch.Tensor, eps : float = 1e-8):\n",
    "    #Cosine Similarity\n",
    "    eps = torch.tensor(eps, device=x1.device)\n",
    "    norms1 = x1.norm(dim=1).unsqueeze_(1).max(eps)\n",
    "    norms2 = x2.norm(dim=1).unsqueeze_(0).max(eps)\n",
    "    cdist = x1 @ x2.T\n",
    "    cdist.div_(norms1).div_(norms2)\n",
    "    return cdist\n",
    "class NeuralHD:\n",
    "    def __init__(self, classes : int, features : int, dim : int = 400, batch_size=1):\n",
    "        #Configure for hdb, hdc, and hde classes\n",
    "        self.param=Config.config\n",
    "        self.param['nClasses'] = classes\n",
    "        self.param['nFeatures']= features\n",
    "        #hypervector size\n",
    "        self.param['D']=dim\n",
    "        self.param['lr']=.0001\n",
    "        self.batch_size=batch_size\n",
    "        self.base = torch.empty(self.param['D']).uniform_(0.0, 2*math.pi)\n",
    "        #encoder\n",
    "        self.hde=None\n",
    "        #classifier\n",
    "        self.hdc=None\n",
    "        # Initialize basis in gaussian distribution\n",
    "        self.basis = torch.normal(0,1,size=(self.param[\"D\"],self.param[\"nFeatures\"]))\n",
    "        # Initialize classification hypervectors\n",
    "        self.classes = torch.zeros((self.param['nClasses'], self.param['D']))\n",
    "        self.prevacc=0\n",
    "        # self.param['lr']=.1\n",
    "        # self.hdc = HD_classifier(self.param[\"D\"], self.param[\"nClasses\"], 0)\n",
    "        self.trainaccuracies=[]\n",
    "        self.testaccuracies=[]\n",
    "        self.medians=[]\n",
    "    def __call__(self, x : torch.Tensor):\n",
    "        #return predicted values\n",
    "        return self.predict(x)\n",
    "    def encode(self,x):\n",
    "        n = x.size(0)\n",
    "        bsize = min([x.size(1),1024])\n",
    "        h = torch.empty(n, self.basis.shape[0], device=x.device, dtype=x.dtype)\n",
    "        temp = torch.empty(bsize, self.basis.shape[0], device=x.device, dtype=x.dtype)\n",
    "\n",
    "        # we need batches to remove memory usage\n",
    "        for i in range(0, n, bsize):\n",
    "            torch.matmul(x[i:i+bsize], self.basis.T, out=temp)\n",
    "\n",
    "            # self.noise ... I haven't seen any indication that it works better \n",
    "            # if self.noise:\n",
    "            torch.add(temp, self.base, out=h[i:i+bsize])#h[i:i+bsize]=temp# torch.add(temp, self.base, out=h[i:i+bsize])\n",
    "            # else:\n",
    "            # h[i:i+bsize]=temp\n",
    "\n",
    "            h[i:i+bsize].cos_()#.mul_(temp.sin_())\n",
    "        # print(h.shape)\n",
    "        return h\n",
    "    def train(self,h,y):\n",
    "        # r=torch.randperm(y.size(0))\n",
    "        # y=y[r]\n",
    "        # h=h[r,:]\n",
    "        n = h.size(0)\n",
    "        batch_size = min([y.size(0), self.batch_size])#64\n",
    "        for i in range(0, n, batch_size):\n",
    "            h_ = h[i:i+batch_size]\n",
    "            y_ = y[i:i+batch_size]\n",
    "            scores = cos_cdist(h_, self.classes)#cos\n",
    "            y_pred = scores.argmax(1)\n",
    "            wrong = y_ != y_pred\n",
    "\n",
    "            # computes alphas to update model\n",
    "            # alpha1 = 1 - delta[lbl] -- the true label coefs\n",
    "            # alpha2 = delta[max] - 1 -- the prediction coefs\n",
    "            aranged = torch.arange(h_.size(0), device=h_.device)\n",
    "            alpha1 = (1.0 - scores[aranged,y_]).unsqueeze_(1)\n",
    "            alpha2 = (scores[aranged,y_pred] - 1.0).unsqueeze_(1)\n",
    "\n",
    "            for lbl in y_.unique():\n",
    "                m1 = wrong & (y_ == lbl) # mask of missed true lbl\n",
    "                m2 = wrong & (y_pred == lbl) # mask of wrong preds\n",
    "                self.classes[lbl] += self.param['lr']*(alpha1[m1]*h_[m1]).sum(0)\n",
    "                self.classes[lbl] += self.param['lr']*(alpha2[m2]*h_[m2]).sum(0)\n",
    "            # if self.test(h,y)<self.prevacc:\n",
    "            #     for lbl in y_.unique():\n",
    "            #         m1 = wrong & (y_ == lbl) # mask of missed true lbl\n",
    "            #         m2 = wrong & (y_pred == lbl) # mask of wrong preds\n",
    "            #         self.classes[lbl] -= self.param['lr']*(alpha1[m1]*h_[m1]).sum(0)\n",
    "            #         self.classes[lbl] -= self.param['lr']*(alpha2[m2]*h_[m2]).sum(0)\n",
    "            # else:\n",
    "            #     self.prevacc=self.test(h,y)\n",
    "    def train2(self,h,y):\n",
    "        # def fit(self, data, label, param = None):\n",
    "\n",
    "        assert self.param[\"D\"] == h.size(1)\n",
    "        #if self.first_fit:\n",
    "        #    sys.stderr.write(\"Fitting with configuration: %s \\n\" % str([(k,param[k]) for k in self.options]))\n",
    "\n",
    "        # Actual fitting\n",
    "\n",
    "        # handling dropout\n",
    "\n",
    "        # fit\n",
    "        r = torch.randperm(h.shape[0])\n",
    "        correct = 0\n",
    "        count = 0\n",
    "        for i in r:\n",
    "            sample = h[i] \n",
    "            answer = y[i]\n",
    "            #maxVal = -1\n",
    "            #guess = -1\n",
    "            #for m in range(self.nClasses):\n",
    "            #    val = kernel(self.classes[m], sample)\n",
    "            #    if val > maxVal:\n",
    "            #        maxVal = val\n",
    "            #        guess = m\n",
    "            vals = cos_cdist(sample.unsqueeze(1).T, self.classes)\n",
    "            # print(vals)\n",
    "            guess = torch.argmax(vals)\n",
    "            if guess != answer:\n",
    "                self.classes[guess]-=self.param['lr']*h[i]*(1-vals[0,guess])\n",
    "                self.classes[answer]+=self.param['lr']*h[i]*(1-vals[0,answer])\n",
    "                # acc=self.test2(h[r][:100],y)\n",
    "                # if acc<=self.prevacc:\n",
    "                #     self.classes[guess]+=self.param['lr']*h[i]\n",
    "                #     self.classes[answer]-=self.param['lr']*h[i]\n",
    "                # else:\n",
    "                #     self.prevacc=acc\n",
    "            else:\n",
    "                correct += 1\n",
    "            count += 1\n",
    "        return correct / count\n",
    "    \n",
    "    def train3(self,h,y):\n",
    "        # def fit(self, data, label, param = None):\n",
    "\n",
    "        assert self.param[\"D\"] == h.size(1)\n",
    "        #if self.first_fit:\n",
    "        #    sys.stderr.write(\"Fitting with configuration: %s \\n\" % str([(k,param[k]) for k in self.options]))\n",
    "\n",
    "        # Actual fitting\n",
    "\n",
    "        # handling dropout\n",
    "\n",
    "        # fit\n",
    "        r = torch.randperm(y.size(0))\n",
    "        y=y[r]\n",
    "        h=h[r,:]\n",
    "        correct = 0\n",
    "        count = 0\n",
    "        for i in range(0,y.size(0),self.batch_size):\n",
    "            sample = h[i:i+self.batch_size] \n",
    "            answers = y[i:i+self.batch_size]\n",
    "            #maxVal = -1\n",
    "            #guess = -1\n",
    "            #for m in range(self.nClasses):\n",
    "            #    val = kernel(self.classes[m], sample)\n",
    "            #    if val > maxVal:\n",
    "            #        maxVal = val\n",
    "            #        guess = m\n",
    "            vals = cos_cdist(sample, self.classes)\n",
    "            # print(vals)\n",
    "            guesses = vals.argmax(1)\n",
    "            # print(guesses)\n",
    "            for j in range(0,answers.size(0)):\n",
    "                if guesses[j] != answers[j]:\n",
    "                    self.classes[guesses[j]]-=self.param['lr']*h[i+j]*(1-vals[0,guesses[j]])\n",
    "                    self.classes[answers[j]]+=self.param['lr']*h[i+j]*(1-vals[0,answers[j]])\n",
    "                    # acc=self.test2(h[r][:100],y)\n",
    "                    # if acc<=self.prevacc:\n",
    "                    #     self.classes[guess]+=self.param['lr']*h[i]\n",
    "                    #     self.classes[answer]-=self.param['lr']*h[i]\n",
    "                    # else:\n",
    "                    #     self.prevacc=acc\n",
    "                else:\n",
    "                    correct += 1\n",
    "                count += 1\n",
    "        return correct / count\n",
    "\n",
    "    def predict(self,x):\n",
    "        #return predictions based on similarity of encoded inputs to classification hypervectors\n",
    "        return  cos_cdist(self.encode(x), self.classes).argmax(1)\n",
    "    def fit(self,traindata, trainlabels,\n",
    "                   epochs,\n",
    "                   regenloops,  # list of effective dimensions to reach \n",
    "                   fractionToDrop # drop/regen rate \n",
    "                    ):\n",
    "        # find encoded training vectors\n",
    "\n",
    "        # calculate amount of dropped dimensions based on percent and original dimension\n",
    "        amountDrop = int(fractionToDrop * self.param['D'])#self.param.D?\n",
    "        # print(\"Updating times:\", regenloops)\n",
    "\n",
    "        for i in range(regenloops+1): # For each eDs to reach, will checkpoints\n",
    "            # compute new encoded data\n",
    "            trainencoded = self.encode(traindata)\n",
    "            testencoded = self.encode(x_testtorch)\n",
    "            \n",
    "            # print(\"regenloop: \" + str(i))\n",
    "            # train for specified number of epochs\n",
    "            # Do the train \n",
    "            self.prevacc=0\n",
    "            iterscorestrain=[]\n",
    "            iterscorestest=[]\n",
    "            maxval=0\n",
    "            temp=None\n",
    "            for j in range(epochs):\n",
    "                # do one pass of training\n",
    "                # print(self.classes[:,8])\n",
    "                result=self.train3(trainencoded, trainlabels)\n",
    "                # print(result)\n",
    "                trainaccuracy= self.test(trainencoded,trainlabels)\n",
    "                testaccuracy= self.test(testencoded,y_testtorch)\n",
    "                iterscorestrain.append(trainaccuracy)\n",
    "                iterscorestest.append(testaccuracy)\n",
    "\n",
    "                if trainaccuracy>maxval:\n",
    "                    temp=copy.deepcopy(self.classes)\n",
    "                    maxval=trainaccuracy\n",
    "                    print(testaccuracy)\n",
    "                # print(j)\n",
    "            self.classes=temp\n",
    "            \n",
    "            self.trainaccuracies+=iterscorestrain\n",
    "            self.testaccuracies+=iterscorestest\n",
    "            self.medians.append(np.median(np.array(iterscorestrain)))\n",
    "                # print(self.prevacc)\n",
    "            #if its the last regeneration training, stop before doing another dimension drop; stop if 100% accuracy\n",
    "            if i==regenloops:\n",
    "                return #self.hdc,self.hde - unnecessary now that hdc and hde are within a class\n",
    "            # print(\"regen\" +str(i))\n",
    "            #do the dimension drop and regeneration\n",
    "            normed_classes = torch.nn.functional.normalize(self.classes)\n",
    "            #calculate variances for each dimension\n",
    "            var = torch.var(normed_classes, 0) \n",
    "            assert len(var) == self.param['D']\n",
    "            # rank each entry in variances from smallest to largest\n",
    "            order = torch.argsort(var)\n",
    "            #drop amountDrop bases\n",
    "            toDrop = order[:amountDrop]\n",
    "            #            ----------------\n",
    "            #attempted reverse drop\n",
    "            # if amountDrop<0:\n",
    "            #     toDrop = order[-amountDrop:]\n",
    "            #            ----------------\n",
    "            #Update basis\n",
    "            #For each dimension designated to be dropped\n",
    "            for i in toDrop:\n",
    "                #generate a new ith vector in the basis\n",
    "                self.basis[i] = torch.normal(self.param[\"mu\"],self.param[\"sigma\"], size=(self.param['nFeatures'],))\n",
    "            #Update Classes\n",
    "            #            --------------\n",
    "            #This code was left out. Maybe useful?\n",
    "            for i in toDrop:\n",
    "                self.classes[:,i] = torch.zeros(self.param['nClasses'])\n",
    "            #            --------------\n",
    "\n",
    "            self.classes=torch.nn.functional.normalize(self.classes)\n",
    "            # self.batch_size=int(np.ceil(self.batch_size/2))\n",
    "            # if self.batch_size==1:\n",
    "            #     self.param['lr']=self.param['lr']/2\n",
    "        return \"error\",\"error\"\n",
    "    def _iterative_fit(self, h, y, lr, epochs):\n",
    "        h=self.encode(h)\n",
    "        n = h.size(0)\n",
    "        for epoch in range(epochs):\n",
    "            for i in range(0, n, self.batch_size):\n",
    "                h_ = h[i:i+self.batch_size]\n",
    "                y_ = y[i:i+self.batch_size]\n",
    "                scores = cos_cdist(h_, self.classes)\n",
    "                y_pred = scores.argmax(1)\n",
    "                wrong = y_ != y_pred\n",
    "\n",
    "                # computes alphas to update model\n",
    "                # alpha1 = 1 - delta[lbl] -- the true label coefs\n",
    "                # alpha2 = delta[max] - 1 -- the prediction coefs\n",
    "                aranged = torch.arange(h_.size(0), device=h_.device)\n",
    "                alpha1 = (1.0 - scores[aranged,y_]).unsqueeze_(1)\n",
    "                alpha2 = (scores[aranged,y_pred] - 1.0).unsqueeze_(1)\n",
    "\n",
    "                for lbl in y_.unique():\n",
    "                    m1 = wrong & (y_ == lbl) # mask of missed true lbl\n",
    "                    m2 = wrong & (y_pred == lbl) # mask of wrong preds\n",
    "                    self.classes[lbl] += lr*(alpha1[m1]*h_[m1]).sum(0)\n",
    "                    self.classes[lbl] += lr*(alpha2[m2]*h_[m2]).sum(0)\n",
    "    def test(self,x_encoded, y_labels):\n",
    "            yhat= cos_cdist(x_encoded, self.classes).argmax(1)\n",
    "            return (yhat==y_labels).float().mean()\n",
    "    def test2(self,x_encoded,y_labels):\n",
    "        yhat=torch.zeros(y_labels.size(0))\n",
    "        i=0\n",
    "        for v in x_encoded:\n",
    "            sims=torch.matmul(v,self.classes.T)\n",
    "            yhat[i]=torch.argmax(sims)\n",
    "            i+=1\n",
    "        return (yhat==y_labels).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9510)\n",
      "tensor(0.9514)\n",
      "tensor(0.9507)\n",
      "tensor(0.9499)\n",
      "tensor(0.9514)\n",
      "tensor(0.9547)\n",
      "tensor(0.9485)\n",
      "tensor(0.9514)\n",
      "tensor(0.9525)\n",
      "tensor(0.9540)\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "    model=NeuralHD(len(np.unique(y_test)),xtrain.shape[1],1000,batch_size=2)\n",
    "    model.fit(xtraintorch,ytraintorch,15,4,.1)\n",
    "    print(get_class_accuracy_breakdown(model,x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[18.9762, -2.2948, 17.3706, 12.9578, 15.8873,  6.4624, -3.7157, -1.8157],\n",
       "        [ 4.2852, -0.0717,  3.9104,  2.5219,  3.0919,  2.4518,  1.2516, -0.2155],\n",
       "        [ 7.7497,  1.9047,  6.8380,  7.1132,  5.0291,  4.9828,  1.7641,  2.8609],\n",
       "        [ 9.7751, -2.5286,  7.6820,  6.1554,  5.4943,  0.4095, -2.2018, -2.2142],\n",
       "        [ 5.5822,  0.4759,  5.8200,  6.4082,  4.0979,  3.8323,  1.7368,  2.7490],\n",
       "        [16.8791,  8.8631, 12.9147, 16.7686, 12.3619, 14.8518,  1.8588,  7.2048],\n",
       "        [ 6.8888, -1.0077,  5.3076,  4.8506,  7.7815,  0.4140, -1.3307,  1.1078],\n",
       "        [ 5.3819,  1.4078,  3.6992,  4.5307,  4.0256,  3.9478,  0.0463,  1.6894],\n",
       "        [ 0.5475,  0.1348,  0.4518,  0.4825,  0.3511,  0.3310,  0.0261,  0.1219]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exper[r,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval=[yhat[i]==y_test[i] for i in range(len(y_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8151, 257])"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtraintorch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9374)\n",
      "tensor(0.9507)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-630-c0242e5ea5a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOnlinehd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOnlineHD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbootstrap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.037\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_pass_fit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_class_accuracy_breakdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Files/Research/Cybersecurity/onlinehd/onlinehd.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, encoded, lr, epochs, batch_size, one_pass_fit, bootstrap)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mone_pass_fit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_one_pass_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbootstrap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterative_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbootstrap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Files/Research/Cybersecurity/onlinehd/onlinehd.py\u001b[0m in \u001b[0;36m_iterative_fit\u001b[0;34m(self, h, y, lr, epochs, batch_size)\u001b[0m\n\u001b[1;32m    256\u001b[0m                     \u001b[0mm1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrong\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlbl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# mask of missed true lbl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                     \u001b[0mm2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrong\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlbl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# mask of wrong preds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlbl\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mh_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlbl\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mh_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import onlinehd as Onlinehd\n",
    "import warnings\n",
    "for i in range(0,10):\n",
    "    model = Onlinehd.OnlineHD(len(np.unique(y_test)), x_test.shape[1], dim=1000)\n",
    "    model.fit(torch.from_numpy(xtrain),torch.from_numpy(ytrain), bootstrap=64, lr=.037, epochs=150, one_pass_fit=False)\n",
    "    print(get_class_accuracy_breakdown(model,x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8969)\n",
      "tensor(0.9334)\n",
      "tensor(0.9437)\n",
      "tensor(0.9323)\n",
      "tensor(0.9481)\n",
      "tensor(0.9481)\n",
      "tensor(0.9492)\n",
      "tensor(0.9518)\n",
      "tensor(0.9522)\n",
      "tensor(0.9507)\n",
      "tensor(0.9507)\n",
      "tensor(0.9518)\n",
      "tensor(0.9522)\n",
      "tensor(0.9529)\n",
      "tensor(0.9525)\n",
      "tensor(0.9522)\n",
      "tensor(0.9525)\n",
      "tensor(0.9481)\n",
      "tensor(0.9481)\n",
      "tensor(0.9507)\n",
      "tensor(0.9533)\n",
      "tensor(0.9536)\n",
      "tensor(0.9551)\n",
      "tensor(0.9529)\n",
      "tensor(0.9536)\n",
      "tensor(0.9555)\n",
      "tensor(0.9547)\n",
      "tensor(0.9569)\n",
      "tensor(0.9522)\n",
      "tensor(0.9544)\n",
      "tensor(0.9540)\n",
      "tensor(0.9569)\n"
     ]
    }
   ],
   "source": [
    "model=NeuralHD(len(np.unique(y_test)),xtrain.shape[1],1000,batch_size=4)\n",
    "model.fit(xtraintorch,ytraintorch,30,5,.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0 accuracy: tensor(0.9360)\n",
      "points: 406\n",
      "class 1 accuracy: tensor(0.9525)\n",
      "points: 589\n",
      "class 2 accuracy: tensor(0.9945)\n",
      "points: 730\n",
      "class 3 accuracy: tensor(0.8774)\n",
      "points: 106\n",
      "class 4 accuracy: tensor(0.2857)\n",
      "points: 7\n",
      "class 5 accuracy: tensor(0.8895)\n",
      "points: 181\n",
      "class 6 accuracy: tensor(0.9515)\n",
      "points: 103\n",
      "class 7 accuracy: tensor(0.9196)\n",
      "points: 336\n",
      "class 8 accuracy: tensor(0.9073)\n",
      "points: 259\n",
      "tensor(0.9441)\n"
     ]
    }
   ],
   "source": [
    "accuracies=[]\n",
    "points=[]\n",
    "for i in range (0,9):\n",
    "    yhat= model(x_testtorch[y_testtorch==i])\n",
    "    acc = (yhat==i).float().mean()\n",
    "    accuracies.append(acc)\n",
    "    points.append(len(yhat))\n",
    "    print('class '+str(i)+' accuracy: ' +str(acc))\n",
    "    print('points: '+ str(len(yhat)))\n",
    "print(sum([accuracies[i]*points[i] for i in range(0,len(accuracies))])/sum(points))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
