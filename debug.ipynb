{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import time\n",
    "import torch\n",
    "import sklearn.datasets\n",
    "import sklearn.preprocessing\n",
    "import sklearn.model_selection\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.datasets import FashionMNIST as FMNIST\n",
    "from torchvision.datasets import EMNIST\n",
    "import torchvision.transforms as transforms\n",
    "import tensorflow as tf\n",
    "import random as r\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam, SGD, Adagrad, Adadelta, RMSprop\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Activation, BatchNormalization\n",
    "import sklearn\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "import time\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "import joblib\n",
    "from tqdm import tqdm_notebook\n",
    "import copy\n",
    "\n",
    "import Config\n",
    "import Dataloader as DL\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets=[\n",
    "    \"KDD Cup 1999\",                            #0\n",
    "    \"Microsoft Challenge BIG 2015\"             #1\n",
    "]\n",
    "presets = {\n",
    "    \"KDD Cup 1999\": {\n",
    "        \"NeuralHD\": [300,2,3,.1],\n",
    "        \"OnlineHD\": [300,1.0,.1,30,True],\n",
    "        \"MLP\": [100,5,.001],\n",
    "        \"SVM\": [10000]\n",
    "    },\n",
    "    \"Microsoft Challenge BIG 2015\": {\n",
    "        \"NeuralHD\": [3000,6,10,.1],\n",
    "        \"OnlineHD\": [3000,1.0,.1,30,True],\n",
    "        \"MLP\": [100,30,.001],\n",
    "        \"SVM\": [None]\n",
    "    }\n",
    "}\n",
    "def normalized(x,y):\n",
    "    xtrain, x_test, ytrain, y_test = None,None,None,None\n",
    "    x, x_test, y, y_test = sklearn.model_selection.train_test_split(x, y, shuffle=True)\n",
    "    scaler = sklearn.preprocessing.Normalizer().fit(x)\n",
    "    x = scaler.transform(x)\n",
    "    x_test = scaler.transform(x_test)\n",
    "\n",
    "    # changes data to pytorch's tensors\n",
    "    x = torch.from_numpy(x).float()\n",
    "    y = torch.from_numpy(y).long()\n",
    "    x_test = torch.from_numpy(x_test).float()\n",
    "    y_test = torch.from_numpy(y_test).long()\n",
    "    return x.numpy(), x_test.numpy(), y.numpy(), y_test.numpy(), scaler\n",
    "def getuniquevalues(columnname,df):\n",
    "    values={}\n",
    "    i=0\n",
    "    for entry in df[columnname]:\n",
    "        if entry not in values:\n",
    "            values[entry]=i\n",
    "            i+=1\n",
    "    return values\n",
    "def get_dataset(name):\n",
    "    if name==datasets[0]:\n",
    "        path=\"../../Data/\"\n",
    "        attacks_types = {\n",
    "            'normal': 'normal','back': 'dos','buffer_overflow': 'u2r','ftp_write': 'r2l','guess_passwd': 'r2l',\n",
    "        'imap': 'r2l','ipsweep': 'probe','land': 'dos','loadmodule': 'u2r','multihop': 'r2l','neptune': 'dos',\n",
    "        'nmap': 'probe','perl': 'u2r','phf': 'r2l','pod': 'dos','portsweep': 'probe','rootkit': 'u2r','satan': 'probe',\n",
    "        'smurf': 'dos','spy': 'r2l','teardrop': 'dos','warezclient': 'r2l','warezmaster': 'r2l',\n",
    "        }\n",
    "        cols =\"\"\"duration,protocol_type,service,flag,src_bytes,dst_bytes,land,wrong_fragment,\n",
    "        urgent,hot,num_failed_logins,logged_in,num_compromised,root_shell,su_attempted,num_root,\n",
    "        num_file_creations,num_shells,num_access_files,num_outbound_cmds,is_host_login,is_guest_login,\n",
    "        count,srv_count,serror_rate,srv_serror_rate,rerror_rate,srv_rerror_rate,same_srv_rate,\n",
    "        diff_srv_rate,srv_diff_host_rate,dst_host_count,dst_host_srv_count,dst_host_same_srv_rate,\n",
    "        dst_host_diff_srv_rate,dst_host_same_src_port_rate,dst_host_srv_diff_host_rate,\n",
    "        dst_host_serror_rate,dst_host_srv_serror_rate,dst_host_rerror_rate,dst_host_srv_rerror_rate\"\"\"\n",
    "        \n",
    "        columns =[]\n",
    "        for c in cols.split(','):\n",
    "            if(c.strip()):\n",
    "                columns.append(c.strip())\n",
    "        print(len(columns))\n",
    "        columns.append('target')\n",
    "        print(len(columns))\n",
    "\n",
    "        attack_categories=[\"dos\",\"u2r\",\"r2l\",'probe','normal']\n",
    "        df = pd.read_csv(path+\"kddcup.data_10_percent.gz\", names = columns)\n",
    "        df['Attack Type'] = df.target.apply(lambda r:attacks_types[r[:-1]])\n",
    "        del df['target']\n",
    "        df.head()\n",
    "        num_cols = df._get_numeric_data().columns\n",
    "        \n",
    "        cate_cols = list(set(df.columns)-set(num_cols))\n",
    "        cate_cols.remove('Attack Type')\n",
    "        for col in cate_cols:\n",
    "            df[col]=df[col].map(getuniquevalues(col,df))\n",
    "        data=df.to_numpy()\n",
    "        Y=df['Attack Type'].map(getuniquevalues('Attack Type',df))\n",
    "        Y=Y.to_numpy()\n",
    "        X=data[:,:-1]\n",
    "        print(Y.shape)\n",
    "        print(X.shape)\n",
    "        print(getuniquevalues('Attack Type',df))\n",
    "        xtrain, x_test, ytrain, y_test,scaler= normalized(X,Y)\n",
    "    if name==datasets[1]:\n",
    "        path=\"../../Data/malware-classification/\"\n",
    "        map={}\n",
    "        mapping=pd.read_csv(path + \"trainLabels.csv\")\n",
    "        Y=mapping[\"Class\"].to_numpy()\n",
    "        for i in range(0,len(Y)):\n",
    "            map[mapping[\"Id\"][i]]=mapping[\"Class\"][i]-1\n",
    "        byte_features=pd.read_csv(path+\"result.csv\")\n",
    "        byte_features['ID']  = byte_features['ID'].str.split('.').str[0]\n",
    "        byte_features.head(3)\n",
    "        byte_features['ID']=byte_features['ID'].map(map)\n",
    "        data=byte_features.to_numpy()\n",
    "        X=data[:,1:]\n",
    "        Y=data[:,0]\n",
    "        xtrain, x_test, ytrain, y_test,scaler= normalized(X,Y)\n",
    "    return xtrain,x_test,ytrain,y_test\n",
    "\n",
    "datasetname=\"Microsoft Challenge BIG 2015\"\n",
    "\n",
    "xtrain,x_test,ytrain,y_test=get_dataset(datasetname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAASnklEQVR4nO3dfbBddX3v8ffHBLWKtyQmTSEJDdemtrFTkEkBr63XSgcT+4CdthTHYkq16XSQ2o6dXvS2xbZ6r+30geq13IsajdXyMEpr6uADUjuU6YgEpCggQwZ5SAgQDeADXhH99o/9O3Q3Oc852fukv/drZs9Z67d+a63vXpPzWSu/tc7eqSokSX14yrgLkCSNjqEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+HRZKPJtmy0H1HIcmPJ7lj3HXMRZJ/SvKacdehxc/Q15OSfG3o9Z0k3xiaf+VctlVVm6tq+0L3nYskL27v42tJvprkjiTnzqKef66q585hH7unWf7RoWP4rSSPD83/32nWqyTfP5sa5ioDb06yJ8mj7YTxvKHlZyX5lySPJfmnKWr7+tD7eNfQsp9I8qm23bsPR/06NEvHXYAWj6o6emK6/cK+pqo+eWC/JEur6olR1nYI7q+qNUkCnAl8MMn1VXXbKHZeVZsnppO8F9hdVb83in1P4xeBXwV+DLgHeDPwN8DJbfl+4CLgB4GXTLGNE6tq1yTtXwe2AZcCb1y4krVQvNLXjCauZpP8jyQPAO9JsizJR5LsS/Jwm14ztM6Tww1JfiXJdUn+rPX9YpLN8+x7QpJr25X7J5O8I8n7Z3oPNfD3wMPAhiRPS3JRkvvb66IkTxt+v0P7vDvJ7yS5pV3BXp7k6UmeCXwUOG7oqve4ORzXX0uyK8n+JDsm1k1ybevyr22bvzTT8Z6jE4Drququqvo28H5gw9Cx+mRVXQHcP9cNV9VnqupvgLvmWZsOM0Nfs/W9wHLg+4CtDP7tvKfNHw98A/g/06x/KnAHsAL4U+Dd7ep7rn3/FvgM8GzgTcA5syk+yVOS/BxwDPA54H8CpwEnAScCpwDTXYGfBWxiEJg/AvxKVX0d2MzgfxNHt9esgjLJS4D/3bZ7LIMr7ssAqupFrduJbZuXM4fjneT4JI8kOX6K3V8GPCfJDyQ5CtgCfGw2dQ+5NskDSa5Msm6O62qMHN7RbH0HuLCqvtnmvwF8aGJhkrcAn5pm/Xuq6p2t73bgr4FVwAOz7ZvkqcCPAqdX1ePAdUl2zFD3cUkeafXfC5xTVXdkcI/i/Kp6qO3nD4H/B/z+FNt520SgJ/kHBieLQ/FKYFtV3dS2+Qbg4STrquruAztX1ZeZ5fGuqnsZnNymshe4jsGJ9dvAfUw9jDOZ/w58GngGg6GhjyQ56Qga8uuaoa/Z2ldV/39iJskzgL9kcPW7rDU/K8mSNmRwoCfDvaoeaxfuR0/Sb7q+K4D9VfXYUN/7gLXT1H1/VU02DHIcg6vrCfe0tqkMn5wem6HvbBwH3DQxU1VfS/JlYDVw94Gd53G8p/MHDE6eaxm8r18G/jHJ8w44tpOqqonhp8eTvA74CvBDDP4HpUXO4R3N1oEfx/p64LnAqVX1X4CJIYmphmwWwl5geQvACdMF/nTuZzBUMuF45jGGzcHHZV77b/cHng3smaL/Qh7vk4DLq2p3VT1RVe9lcCLZMO1aU6t51qExMPQ1X89iMMTzSJLlwIWHe4dVdQ+wE3hTkqcmeQHwM/Pc3KXA7yVZmWQFg6vfGW8IT+JB4NlJvnse+z83yUntBvL/Aq4fGtp5EPivQ/0X8njfAPxiklXtXsc5wFHALoAkS5I8ncFIwFPaTeuj2rLntZqXJDka+HMGJ6rb2/KntHWPGszm6W1YTouEoa/5ugj4LuBLDMZ353ojcL5eCbwA+DKD8eTLgW9Ou8bk3szgBHILg2GJm1rbnFTVFxgE+F3t5umshn3ao7C/z2Ccfi/wHODsoS5vAra3bZ7FHI53u5H7tWlu5P4J8K/AzcAjwG8DP19Vj7Tl5zA4wVwM/HibfmdbtorBMf8Kgyd01gE/XVXfastf1Ppfxb/fcP7E1EdCoxa/REVHsiSXA1+oqsP+Pw3pPwOv9HVESfKjSZ7ThhE2MfiDq78fc1nSEcOnd3Sk+V7gSgY3PXcDv1FVnx1vSdKRw+EdSeqIwzuS1JFFPbyzYsWKWrdu3bjLkKQjyo033vilqlo52bJFHfrr1q1j586d4y5Dko4oSe6ZapnDO5LUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1JFF/Re5Wnj7z5/qezUOj+Vvv3ek+5M0Pa/0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6siMoZ9kbZJPJbktya1JXtfalye5Osmd7eey1p4kb0uyK8ktSU4e2taW1v/OJFsO39uSJE1mNlf6TwCvr6oNwGnAeUk2ABcA11TVeuCaNg+wGVjfXluBi2FwkgAuBE4FTgEunDhRSJJGY8bQr6q9VXVTm/4qcDuwGjgT2N66bQde3qbPBN5XA58GjklyLPBS4Oqq2l9VDwNXA5sW8s1IkqY3pzH9JOuA5wPXA6uqam9b9ACwqk2vBu4bWm13a5uq/cB9bE2yM8nOffv2zaU8SdIMZh36SY4GPgT8VlV9ZXhZVRVQC1FQVV1SVRurauPKlSsXYpOSpGZWoZ/kKAaB/4GqurI1P9iGbWg/H2rte4C1Q6uvaW1TtUuSRmQ2T+8EeDdwe1X9xdCiHcDEEzhbgA8Ptb+qPcVzGvBoGwb6OHBGkmXtBu4ZrU2SNCJLZ9HnhcA5wOeS3Nza3gi8FbgiyauBe4Cz2rKrgJcBu4DHgHMBqmp/kj8Gbmj9/qiq9i/Em5Akzc6MoV9V1wGZYvHpk/Qv4LwptrUN2DaXAiVJC8e/yJWkjhj6ktQRQ1+SOmLoS1JHDH1J6shsHtnUIdp//vEj3d/yt9870v1JOnJ4pS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqyIyhn2RbkoeSfH6o7U1J9iS5ub1eNrTsDUl2JbkjyUuH2je1tl1JLlj4tyJJmslsrvTfC2yapP0vq+qk9roKIMkG4GzgeW2dv06yJMkS4B3AZmAD8IrWV5I0Qktn6lBV1yZZN8vtnQlcVlXfBL6YZBdwSlu2q6ruAkhyWet729xLliTN16GM6b82yS1t+GdZa1sN3DfUZ3drm6r9IEm2JtmZZOe+ffsOoTxJ0oHmG/oXA88BTgL2An++UAVV1SVVtbGqNq5cuXKhNitJYhbDO5OpqgcnppO8E/hIm90DrB3quqa1MU27JGlE5nWln+TYodmfAyae7NkBnJ3kaUlOANYDnwFuANYnOSHJUxnc7N0x/7IlSfMx45V+kkuBFwMrkuwGLgRenOQkoIC7gV8HqKpbk1zB4AbtE8B5VfXttp3XAh8HlgDbqurWhX4zkqTpzebpnVdM0vzuafq/BXjLJO1XAVfNqTpJ0oLyL3IlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjqydNwFHE77zz9+ZPta/vZ7R7YvSZovr/QlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHZkx9JNsS/JQks8PtS1PcnWSO9vPZa09Sd6WZFeSW5KcPLTOltb/ziRbDs/bkSRNZzZX+u8FNh3QdgFwTVWtB65p8wCbgfXttRW4GAYnCeBC4FTgFODCiROFJGl0Zgz9qroW2H9A85nA9ja9HXj5UPv7auDTwDFJjgVeClxdVfur6mHgag4+kUiSDrP5jumvqqq9bfoBYFWbXg3cN9Rvd2ubqv0gSbYm2Zlk5759++ZZniRpMod8I7eqCqgFqGVie5dU1caq2rhy5cqF2qwkifmH/oNt2Ib286HWvgdYO9RvTWubql2SNELzDf0dwMQTOFuADw+1v6o9xXMa8GgbBvo4cEaSZe0G7hmtTZI0QjN+nn6SS4EXAyuS7GbwFM5bgSuSvBq4Bzirdb8KeBmwC3gMOBegqvYn+WPghtbvj6rqwJvDkqTDbMbQr6pXTLHo9En6FnDeFNvZBmybU3WSuueXIS0s/yJXkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOjLjN2dJkkb7DV5w+L7Fyyt9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6ojfnCUtIqP8dqbD9c1MWty80pekjhj6ktSRQwr9JHcn+VySm5PsbG3Lk1yd5M72c1lrT5K3JdmV5JYkJy/EG5Akzd5CXOn/RFWdVFUb2/wFwDVVtR64ps0DbAbWt9dW4OIF2LckaQ4Ox/DOmcD2Nr0dePlQ+/tq4NPAMUmOPQz7lyRN4VBDv4BPJLkxydbWtqqq9rbpB4BVbXo1cN/Qurtb23+QZGuSnUl27tu37xDLkyQNO9RHNn+sqvYk+R7g6iRfGF5YVZWk5rLBqroEuARg48aNc1pXkjS9Q7rSr6o97edDwN8BpwAPTgzbtJ8Pte57gLVDq69pbZKkEZl36Cd5ZpJnTUwDZwCfB3YAW1q3LcCH2/QO4FXtKZ7TgEeHhoEkSSNwKMM7q4C/SzKxnb+tqo8luQG4IsmrgXuAs1r/q4CXAbuAx4BzD2HfkqR5mHfoV9VdwImTtH8ZOH2S9gLOm+/+JEmHzr/IlaSOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI35dosZilF8LCH41oDTBK31J6oihL0kdMfQlqSOGviR1xBu5kg7ijfb/vLzSl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOLB31DpNsAv4KWAK8q6reOuoapGH7zz9+pPtb/vZ7R7o/adhIr/STLAHeAWwGNgCvSLJhlDVIUs9GPbxzCrCrqu6qqseBy4AzR1yDJHUrVTW6nSW/AGyqqte0+XOAU6vqtUN9tgJb2+xzgTtGVuC/WwF8aQz7Xcw8JgfzmBzMY3KwcRyT76uqlZMtGPmY/kyq6hLgknHWkGRnVW0cZw2LjcfkYB6Tg3lMDrbYjsmoh3f2AGuH5te0NknSCIw69G8A1ic5IclTgbOBHSOuQZK6NdLhnap6IslrgY8zeGRzW1XdOsoaZmmsw0uLlMfkYB6Tg3lMDraojslIb+RKksbLv8iVpI4Y+pLUEUN/SJJNSe5IsivJBeOuZ9ySrE3yqSS3Jbk1yevGXdNikWRJks8m+ci4a1kskhyT5INJvpDk9iQvGHdN45bkt9vvzueTXJrk6eOuydBv/IiIST0BvL6qNgCnAed5TJ70OuD2cRexyPwV8LGq+kHgRDo/PklWA78JbKyqH2bw8MrZ463K0B/mR0QcoKr2VtVNbfqrDH6JV4+3qvFLsgb4KeBd465lsUjy3cCLgHcDVNXjVfXIWItaHJYC35VkKfAM4P4x12PoD1kN3Dc0vxsD7klJ1gHPB64fcymLwUXA7wLfGXMdi8kJwD7gPW3Y611JnjnuosapqvYAfwbcC+wFHq2qT4y3KkNfs5DkaOBDwG9V1VfGXc84Jflp4KGqunHctSwyS4GTgYur6vnA14Gu74slWcZgtOAE4DjgmUl+ebxVGfrD/IiISSQ5ikHgf6Cqrhx3PYvAC4GfTXI3gyHAlyR5/3hLWhR2A7urauJ/gh9kcBLo2U8CX6yqfVX1LeBK4L+NuSZDf4gfEXGAJGEwRnt7Vf3FuOtZDKrqDVW1pqrWMfg38o9VNfart3GrqgeA+5I8tzWdDtw2xpIWg3uB05I8o/0unc4iuLm96D5lc1yOoI+IGKUXAucAn0tyc2t7Y1VdNb6StIidD3ygXTTdBZw75nrGqqquT/JB4CYGT8J9lkXwkQx+DIMkdcThHUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOvJvAr0QvO+SIkIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "points=[]\n",
    "for i in range (0,len(np.unique(ytrain))):\n",
    "    points.append(len(xtrain[ytrain==i]))\n",
    "plt.bar(range(0,len(points)),points, color=np.random.rand(3,))\n",
    "plt.title(\"Training Point Total: \" + str(sum(points)))\n",
    "plt.show()\n",
    "points=[]\n",
    "for i in range (0,len(np.unique(y_test))):\n",
    "    points.append(len(x_test[y_test==i]))\n",
    "plt.bar(range(0,len(points)),points, color=np.random.rand(3,))\n",
    "plt.title(\"Testing Point Total: \" + str(sum(points)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_accuracy_breakdown(model,x_test,y_test, output=False):\n",
    "    acc=[]\n",
    "    points=[]\n",
    "    try:\n",
    "        for i in range (0,len(np.unique(y_test))):\n",
    "            yhat= model.predict(x_test[y_test==i])\n",
    "            if len(yhat.shape)==2:\n",
    "                yhat=np.array([row.argmax() for row in yhat])\n",
    "            acc.append((yhat==i).mean())\n",
    "            points.append(len(yhat))\n",
    "    except:\n",
    "        for i in range (0,len(np.unique(y_test))):\n",
    "            yhat= model.predict(torch.from_numpy(x_test[y_test==i]))\n",
    "            acc.append((yhat==i).float().mean())\n",
    "            points.append(len(yhat))\n",
    "    # print(yhat[:30])\n",
    "    totacc=sum([acc[i]*points[i] for i in range(0,len(acc))])/sum(points)\n",
    "    if output:\n",
    "        plt.bar(range(0,len(acc)),acc,color=np.random.rand(3,))\n",
    "        plt.title(\"Accuracy Total: \" + str(totacc))\n",
    "        plt.show()\n",
    "    return totacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_vector(vector_length, vector_type, param):\n",
    "    #Check for Gaussian kernel\n",
    "    if vector_type == \"Gaussian\":\n",
    "        #parse for mu\n",
    "        mu = param[\"mu\"]\n",
    "        #parse for sigma\n",
    "        sigma = param[\"sigma\"]\n",
    "        #return vector generated from kernel\n",
    "        return np.random.normal(mu, sigma, vector_length)\n",
    "    else:\n",
    "        #all other kernels are currently unsupported\n",
    "        raise Exception(\"Vector type %s not recognized. Abort.\\n\" % vector_type)\n",
    "\n",
    "def vanilla(param):\n",
    "\n",
    "    #create basis as list\n",
    "    basis = []\n",
    "    #hidden dimension is D\n",
    "    for _ in range(param[\"D\"]):\n",
    "        #add one generated vector as a time\n",
    "        basis.append(generate_vector(param[\"nFeatures\"], param[\"vector\"], param))\n",
    "    #make basis numpy array\n",
    "    basis = np.asarray(basis)\n",
    "    return basis\n",
    "\n",
    "\n",
    "\n",
    "        #sys.stderr.write(str(self.basis.shape)+\"\\n\")\n",
    "def updateBasis(basis, param, toChange = None):\n",
    "    # print(\"Updating basis......\")# at the following indices: (None means changing everything)\")\n",
    "    #print(toChange)\n",
    "    #For each dimension designated to be dropped\n",
    "    for i in toChange:\n",
    "        #generate a new ith vector in the basis\n",
    "        basis[i] = generate_vector(param[\"nFeatures\"], param[\"vector\"], param)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0615, -0.3425,  0.6613,  1.7455, -1.0800,  0.8591,  1.2278,  1.1541,\n",
      "        -2.6651, -1.8779,  0.4432, -0.0875,  2.2622, -0.5486,  1.2958,  0.4385,\n",
      "        -0.0572, -0.9011, -1.6294, -0.1109, -0.6423, -0.1771, -0.9261,  0.4149,\n",
      "         0.6867, -0.6668, -1.0673, -0.6161, -0.6045,  1.3496, -0.1471,  2.4156,\n",
      "        -0.2745,  0.6797, -0.9209, -0.0667, -0.1386,  0.8871, -0.1701, -0.3107,\n",
      "        -0.0904,  1.2184,  1.3850, -0.1226, -0.9739, -2.1791,  1.5172, -1.2195,\n",
      "        -0.4422, -0.8619, -1.3536,  0.0532, -0.4930,  0.1446,  1.4669, -1.7427,\n",
      "        -0.8101,  0.2609, -0.6399,  0.7198, -1.8004,  0.0858, -0.6407,  0.2021,\n",
      "        -0.8238, -0.7949,  0.2216,  0.1876,  1.6173, -0.7930, -0.3881,  0.3837,\n",
      "         0.8829,  0.4487, -3.4797, -2.9819,  0.8319, -0.5422,  0.4257,  0.6609,\n",
      "        -0.4198, -0.8094, -0.9177,  0.3370, -0.8803,  0.0578,  0.0897,  1.2807,\n",
      "         0.3296, -0.1290, -0.9246,  0.1832,  0.1525, -0.5853,  1.4780,  0.0209,\n",
      "        -0.0678,  0.3813, -0.6559, -1.6955,  1.8844, -0.5358, -0.1478, -0.2974,\n",
      "         1.4747, -0.0809,  0.5379, -0.7816, -0.2772,  0.5994,  0.1608,  1.5121,\n",
      "         0.3967, -0.1689, -2.3829, -1.0400, -0.4110, -0.7911, -1.2131,  0.1181,\n",
      "         0.8103, -0.2867,  0.1864, -0.6056, -0.5448,  0.6330, -0.4073,  1.2493,\n",
      "         2.6348,  0.5362,  0.2004,  0.5524, -1.5942,  0.5761,  0.8465,  0.3902,\n",
      "        -1.2439, -0.6506, -0.5445,  0.9044, -0.7766, -0.1990, -1.8011,  1.7488,\n",
      "        -0.6092, -1.1562,  2.4411, -0.2465, -0.1398, -0.2868, -2.3649,  0.0348,\n",
      "         1.1168, -0.7505, -0.0917, -0.9452,  0.8753,  0.8671,  0.0927,  0.7921,\n",
      "         0.0439,  1.3453,  0.2544, -1.1407,  1.5494,  0.9176, -0.1817,  0.1263,\n",
      "        -1.7664,  1.2684, -2.7159,  1.0004,  1.2248,  0.4572,  0.0373, -0.1247,\n",
      "         0.3166,  0.3398,  1.4806,  0.7719, -0.5923, -0.4685,  2.1060,  1.3005,\n",
      "         0.1200, -1.9842, -0.0231,  1.0116,  0.7438, -0.8318, -0.9630,  0.8983,\n",
      "         0.3819,  0.3310, -0.4801, -1.5283,  0.3892,  2.4467, -0.8628,  0.5117,\n",
      "        -1.8447, -0.2915, -0.2053, -1.3668, -1.0505,  0.4663, -0.6991,  0.4805,\n",
      "         0.3545,  0.7619, -0.4755, -0.5014, -0.2666, -0.1888, -0.3602,  0.5192,\n",
      "        -0.2872,  0.9761, -0.3836, -0.5129,  0.3500, -1.7206,  0.5772,  1.3796,\n",
      "         1.9602,  0.0353,  1.6552,  0.2081, -0.8384,  0.4340, -0.1964, -1.0894,\n",
      "         1.0991,  0.7580,  1.9802, -0.0581,  1.2508, -0.0784,  1.2117, -1.6137,\n",
      "        -2.5265, -0.6185,  0.4161, -0.2500,  0.0805,  0.6416, -1.2101,  0.1681,\n",
      "        -1.5015, -0.8824, -1.2050, -0.7734, -0.3411, -0.3241,  1.4967, -1.4695,\n",
      "        -1.1534,  2.2811,  0.8661,  0.0947, -0.1418, -2.9438,  0.9384,  1.7272,\n",
      "        -0.9219,  0.5764,  0.6780,  0.1917,  0.4733,  1.3483,  0.7661,  1.1873,\n",
      "         0.0688,  0.1746, -0.4603,  1.1678, -2.1582, -0.9420,  0.3409,  1.6960,\n",
      "        -0.7108, -0.8599, -0.7945,  0.1437, -0.1038,  1.9911,  0.6867,  0.2800,\n",
      "         1.1056, -0.4759, -0.1234, -0.3523, -1.0075,  1.1343,  0.7005,  0.9751,\n",
      "        -1.6830, -0.7133,  0.4398,  0.2369])\n",
      "tensor([ 0.0615, -0.3425,  0.6613,  1.7455, -1.0800,  0.8591,  1.2278,  1.1541,\n",
      "        -2.6651, -1.8779,  0.4432, -0.0875,  2.2622, -0.5486,  1.2958,  0.4385,\n",
      "        -0.0572, -0.9011, -1.6294, -0.1109, -0.6423, -0.1771, -0.9261,  0.4149,\n",
      "         0.6867, -0.6668, -1.0673, -0.6161, -0.6045,  1.3496, -0.1471,  2.4156,\n",
      "        -0.2745,  0.6797, -0.9209, -0.0667, -0.1386,  0.8871, -0.1701, -0.3107,\n",
      "        -0.0904,  1.2184,  1.3850, -0.1226, -0.9739, -2.1791,  1.5172, -1.2195,\n",
      "        -0.4422, -0.8619, -1.3536,  0.0532, -0.4930,  0.1446,  1.4669, -1.7427,\n",
      "        -0.8101,  0.2609, -0.6399,  0.7198, -1.8004,  0.0858, -0.6407,  0.2021,\n",
      "        -0.8238, -0.7949,  0.2216,  0.1876,  1.6173, -0.7930, -0.3881,  0.3837,\n",
      "         0.8829,  0.4487, -3.4797, -2.9819,  0.8319, -0.5422,  0.4257,  0.6609,\n",
      "        -0.4198, -0.8094, -0.9177,  0.3370, -0.8803,  0.0578,  0.0897,  1.2807,\n",
      "         0.3296, -0.1290, -0.9246,  0.1832,  0.1525, -0.5853,  1.4780,  0.0209,\n",
      "        -0.0678,  0.3813, -0.6559, -1.6955,  1.8844, -0.5358, -0.1478, -0.2974,\n",
      "         1.4747, -0.0809,  0.5379, -0.7816, -0.2772,  0.5994,  0.1608,  1.5121,\n",
      "         0.3967, -0.1689, -2.3829, -1.0400, -0.4110, -0.7911, -1.2131,  0.1181,\n",
      "         0.8103, -0.2867,  0.1864, -0.6056, -0.5448,  0.6330, -0.4073,  1.2493,\n",
      "         2.6348,  0.5362,  0.2004,  0.5524, -1.5942,  0.5761,  0.8465,  0.3902,\n",
      "        -1.2439, -0.6506, -0.5445,  0.9044, -0.7766, -0.1990, -1.8011,  1.7488,\n",
      "        -0.6092, -1.1562,  2.4411, -0.2465, -0.1398, -0.2868, -2.3649,  0.0348,\n",
      "         1.1168, -0.7505, -0.0917, -0.9452,  0.8753,  0.8671,  0.0927,  0.7921,\n",
      "         0.0439,  1.3453,  0.2544, -1.1407,  1.5494,  0.9176, -0.1817,  0.1263,\n",
      "        -1.7664,  1.2684, -2.7159,  1.0004,  1.2248,  0.4572,  0.0373, -0.1247,\n",
      "         0.3166,  0.3398,  1.4806,  0.7719, -0.5923, -0.4685,  2.1060,  1.3005,\n",
      "         0.1200, -1.9842, -0.0231,  1.0116,  0.7438, -0.8318, -0.9630,  0.8983,\n",
      "         0.3819,  0.3310, -0.4801, -1.5283,  0.3892,  2.4467, -0.8628,  0.5117,\n",
      "        -1.8447, -0.2915, -0.2053, -1.3668, -1.0505,  0.4663, -0.6991,  0.4805,\n",
      "         0.3545,  0.7619, -0.4755, -0.5014, -0.2666, -0.1888, -0.3602,  0.5192,\n",
      "        -0.2872,  0.9761, -0.3836, -0.5129,  0.3500, -1.7206,  0.5772,  1.3796,\n",
      "         1.9602,  0.0353,  1.6552,  0.2081, -0.8384,  0.4340, -0.1964, -1.0894,\n",
      "         1.0991,  0.7580,  1.9802, -0.0581,  1.2508, -0.0784,  1.2117, -1.6137,\n",
      "        -2.5265, -0.6185,  0.4161, -0.2500,  0.0805,  0.6416, -1.2101,  0.1681,\n",
      "        -1.5015, -0.8824, -1.2050, -0.7734, -0.3411, -0.3241,  1.4967, -1.4695,\n",
      "        -1.1534,  2.2811,  0.8661,  0.0947, -0.1418, -2.9438,  0.9384,  1.7272,\n",
      "        -0.9219,  0.5764,  0.6780,  0.1917,  0.4733,  1.3483,  0.7661,  1.1873,\n",
      "         0.0688,  0.1746, -0.4603,  1.1678, -2.1582, -0.9420,  0.3409,  1.6960,\n",
      "        -0.7108, -0.8599, -0.7945,  0.1437, -0.1038,  1.9911,  0.6867,  0.2800,\n",
      "         1.1056, -0.4759, -0.1234, -0.3523, -1.0075,  1.1343,  0.7005,  0.9751,\n",
      "        -1.6830, -0.7133,  0.4398,  0.2369])\n"
     ]
    }
   ],
   "source": [
    "def generate_vector(vector_length,param):\n",
    "    #return vector generated from gaussian kernel\n",
    "    return torch.normal(param[\"mu\"],param[\"sigma\"] 1, size=(300,))\n",
    "def vanilla(param):\n",
    "    torch.normal(0,1,size=(param[\"D\"],param[\"nFeatures\"]))\n",
    "def updateBasis(basis, param, toChange = None):\n",
    "    # print(\"Updating basis......\")# at the following indices: (None means changing everything)\")\n",
    "    #print(toChange)\n",
    "    #For each dimension designated to be dropped\n",
    "    for i in toChange:\n",
    "        #generate a new ith vector in the basis\n",
    "        basis[i] = generate_vector(param[\"nFeatures\"], param)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Config\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from Config import config, Update_T\n",
    "\n",
    "# n = e^-(|x|^2/(2std^2)) <- gaussian function\n",
    "def gauss(x,y,std):\n",
    "  n = np.linalg.norm(x - y)\n",
    "  n = n ** 2\n",
    "  n = n * -1\n",
    "  n = n / (2 * (std**2))\n",
    "  n = np.exp(n)\n",
    "  return n\n",
    "\n",
    "def poly(x,y,c,d):\n",
    "  return (np.dot(x,y) + c) ** d\n",
    "\n",
    "#  dot product/ gauss product/ cos product\n",
    "def kernel(x,y):\n",
    "  dotKernel = np.dot\n",
    "#   gaussKernel = lambda x, y : gauss(x,y,25)\n",
    "#   polyKernel = lambda x,y : poly(x,y,3,5)\n",
    "#   cosKernel = lambda x,y : np.dot(x,y) / (np.linalg.norm(x) * np.linalg.norm(y))\n",
    "  #k = gaussKernel\n",
    "  #k = polyKernel\n",
    "  k = dotKernel\n",
    "  #k = cosKernel\n",
    "  return k(x,y)\n",
    "\n",
    "class HD_classifier:\n",
    "\n",
    "    # Required parameters for the training it supports; will enhance later\n",
    "    options = [\"one_shot\", \"dropout\", \"lr\"]\n",
    "    # required opts for dropout\n",
    "    options_dropout = [\"dropout_rate\", \"update_type\"]\n",
    "\n",
    "    # id: id associated with the basis/encoded data\n",
    "    def __init__(self, D, nClasses, id):\n",
    "        self.D = D\n",
    "        # number of classes\n",
    "        self.nClasses = nClasses\n",
    "        # classes\n",
    "        self.classes = np.zeros((nClasses, D))\n",
    "        self.counts = np.zeros(nClasses)\n",
    "        # If first fit, print out complete configuration\n",
    "        self.first_fit = True\n",
    "        self.id = id\n",
    "        self.idx_weights = np.ones((D))\n",
    "        self.update_cnts = np.zeros((D))\n",
    "        self.mask = np.ones((D))\n",
    "\n",
    "    def getClasses(self):\n",
    "        return self.classes\n",
    "\n",
    "    def update(self, weight, mask, guess, answer, rate, update_type=Update_T.FULL):\n",
    "        sample = weight * mask\n",
    "        self.counts[guess] += 1\n",
    "        self.counts[answer] += 1\n",
    "        # update hypervector weights\n",
    "        if update_type == Update_T.FULL:\n",
    "            self.classes[guess]  -= rate * weight\n",
    "            self.classes[answer] += rate * weight\n",
    "        elif update_type == Update_T.PARTIAL:\n",
    "            self.classes[guess]  -= rate * sample\n",
    "            self.classes[answer] += rate * weight\n",
    "        elif update_type == Update_T.RPARTIAL:\n",
    "            self.classes[guess]  -= rate * weight\n",
    "            self.classes[answer] += rate * sample\n",
    "        elif update_type == Update_T.MASKED:\n",
    "            self.classes[guess]  -= rate * sample\n",
    "            self.classes[answer] += rate * sample\n",
    "        elif update_type == Update_T.HALF:\n",
    "            self.classes[answer] += rate * weight\n",
    "            self.counts[guess] -= 1\n",
    "        elif update_type == Update_T.WEIGHTED:\n",
    "            self.classes[guess]  -= rate * np.multiply(self.idx_weights, sample)\n",
    "            self.classes[answer] += rate * np.multiply(self.idx_weights, sample)\n",
    "        else:\n",
    "            raise Exception(\"unrecognized Update_T\")\n",
    "\n",
    "    # update class vectors with each sample, once\n",
    "    # return train accuracy\n",
    "    def fit(self, data, label, param = None):\n",
    "\n",
    "        assert self.D == data.shape[1]\n",
    "\n",
    "        # Default parameter\n",
    "        if param is None:\n",
    "            #set default configuration\n",
    "            param = Config.config\n",
    "        for option in self.options:\n",
    "            if option not in param:\n",
    "                #if options are missing, set it to default\n",
    "                param[option] = config[option]\n",
    "        #if self.first_fit:\n",
    "        #    sys.stderr.write(\"Fitting with configuration: %s \\n\" % str([(k,param[k]) for k in self.options]))\n",
    "\n",
    "        # Actual fitting\n",
    "\n",
    "        # handling dropout\n",
    "        mask = np.ones(self.D)\n",
    "        if param[\"masked\"]:\n",
    "            mask = np.copy(self.mask)\n",
    "        elif param[\"dropout\"]:\n",
    "            for option in self.options_dropout:\n",
    "                if option not in param:\n",
    "                    param[option] = config[option]\n",
    "            # Mask for dropout\n",
    "            for i in np.random.choice(self.D, int(self.D * (param[\"drop_rate\"])), replace=False):\n",
    "                mask[i] = 0\n",
    "\n",
    "        # fit\n",
    "        r = list(range(data.shape[0]))\n",
    "        random.shuffle(r)\n",
    "        correct = 0\n",
    "        count = 0\n",
    "        for i in r:\n",
    "            sample = data[i] * mask\n",
    "            assert data[i].shape == mask.shape\n",
    "\n",
    "            answer = label[i]\n",
    "            #maxVal = -1\n",
    "            #guess = -1\n",
    "            #for m in range(self.nClasses):\n",
    "            #    val = kernel(self.classes[m], sample)\n",
    "            #    if val > maxVal:\n",
    "            #        maxVal = val\n",
    "            #        guess = m\n",
    "            vals = np.matmul(sample, self.classes.T)\n",
    "            # print(vals)\n",
    "            guess = np.argmax(vals)\n",
    "            if guess != answer:\n",
    "                self.update(data[i], mask, guess, answer, param[\"lr\"], param[\"update_type\"])\n",
    "            else:\n",
    "                correct += 1\n",
    "            count += 1\n",
    "        self.first_fit = False\n",
    "        return correct / count\n",
    "    def predict(self, data):\n",
    "        # print(data.shape)\n",
    "        assert self.D == data.shape[1]\n",
    "\n",
    "        prediction = []\n",
    "        # fit\n",
    "        for i in range(0,data.shape[0]):\n",
    "            maxVal = -1\n",
    "            guess = -1\n",
    "            for m in range(self.nClasses):\n",
    "                val = kernel(self.classes[m], data[i])\n",
    "                if val > maxVal:\n",
    "                    maxVal = val\n",
    "                    guess = m\n",
    "            prediction.append(guess)\n",
    "        return prediction\n",
    "\n",
    "    # given current classifier value, return:\n",
    "    # Variance of each dimension across the classes, and\n",
    "    # The indices in the order from least variance to greatest\n",
    "    def evaluateBasis(self):\n",
    "        #normed_classes = self.classes/(np.sqrt(np.asarray([self.counts])).T)\n",
    "        #variances = np.var(self.classes, axis = 0)\n",
    "        normed_classes = sklearn.preprocessing.normalize(np.asarray(self.classes), norm='l2')\n",
    "        variances = np.var(normed_classes, axis = 0) \n",
    "        assert len(variances) == self.D\n",
    "        order = np.argsort(variances)\n",
    "        return variances, order\n",
    "\n",
    "    # Some basis are to be update\n",
    "    def updateClasses(self, toChange = None):\n",
    "        if toChange is None:\n",
    "            #self.classes = np.zeros((self.nClasses, self.D))\n",
    "            self.classes = sklearn.preprocessing.normalize(np.asarray(self.classes), norm='l2', axis = 0)\n",
    "            self.counts = np.ones(self.nClasses) # An averaged vector is already in\n",
    "        else:\n",
    "            for i in toChange:\n",
    "                self.classes[:,i] = np.zeros(self.nClasses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump basis and its param into a file, return the name of file\n",
    "def saveEncoded(encoded, labels, id = \"\", data_type = \"unknown\"):\n",
    "    filename = \"encoded_%s_%s.pkl\" % (id, data_type)\n",
    "    sys.stderr.write(\"Dumping data into %s \\n\"%filename)\n",
    "    joblib.dump((encoded, labels), open(filename, \"wb\"), compress=True)\n",
    "    return filename\n",
    "\n",
    "# Load basis from a file\n",
    "def loadEncoded(filename):\n",
    "    encoded, labels = joblib.load(filename)\n",
    "    return encoded, labels\n",
    "\n",
    "\n",
    "# Class: HD_encoder\n",
    "# Use: take in a basis and a noise flag to create instance, call functions to with data to encode\n",
    "class HD_encoder:\n",
    "    def __init__(self, basis, noise=False):\n",
    "        # set basis to encode with\n",
    "        self.basis = basis\n",
    "        self.base = torch.empty(basis.shape[0]).uniform_(0.0, 2*math.pi)\n",
    "        # hypervector dimension\n",
    "        self.D = basis.shape[0]\n",
    "        self.noise=noise\n",
    "        #### Noise not implemented yet\n",
    "        # self.noises = []  \n",
    "        # if noise:\n",
    "        #     self.noises = np.random.uniform(0, 2 * math.pi, self.D)\n",
    "        # else:\n",
    "        #     self.noises = np.zeros(self.D)\n",
    "    def encode(x,basis, base, noise):\n",
    "        n = x.size(0)\n",
    "        bsize = min([x.size(1),1024])\n",
    "        h = torch.empty(n, basis.shape[0], device=x.device, dtype=x.dtype)\n",
    "        temp = torch.empty(bsize, basis.shape[0], device=x.device, dtype=x.dtype)\n",
    "\n",
    "        # we need batches to remove memory usage\n",
    "        for i in range(0, n, bsize):\n",
    "            torch.matmul(x[i:i+bsize], basis.T, out=temp)\n",
    "            if noise:\n",
    "                torch.add(temp, base, out=h[i:i+bsize])#h[i:i+bsize]=temp# torch.add(temp, self.base, out=h[i:i+bsize])\n",
    "            else:\n",
    "                h[i:i+bsize]=temp\n",
    "            h[i:i+bsize].cos_()#.mul_(temp.sin_())\n",
    "        # print(h.shape)\n",
    "        return h\n",
    "    def encodeData(self, data):\n",
    "        # print(self.basis.shape)\n",
    "        # print(data.shape)\n",
    "        #Changed it to do matmul for all data at once\n",
    "        # encoded = np.matmul(self.basis,data.T).T\n",
    "        # #nonlinear activation function\n",
    "        # encoded = np.cos(encoded)\n",
    "        # print(encoded.shape)\n",
    "        return encode(data,self.basis,self.base,self.noise)#encoded\n",
    "        # start = time.time()\n",
    "        #no matrix multiplication errors\n",
    "        assert data.shape[1] == self.basis.shape[1]\n",
    "        # noises = []\n",
    "        encoded = []\n",
    "\n",
    "        for i in range(len(data)):\n",
    "            encoded.append(self.encodeDatum(data[i]))\n",
    "\n",
    "        # end = time.time()\n",
    "        #sys.stderr.write(\"Time spent: %d sec\\n\" % int(end - start))\n",
    "        return np.asarray(encoded)\n",
    "\n",
    "    # Replace basis of the HDE\n",
    "    def updateBasis(self, basis):\n",
    "        self.basis = basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class NeuralHD:\n",
    "    def __init__(self, classes : int, features : int, dim : int = 400):\n",
    "        #Configure for hdb, hdc, and hde classes\n",
    "        self.param=Config.config\n",
    "        self.param['nClasses'] = classes\n",
    "        self.param['nFeatures']= features\n",
    "        #hypervector size\n",
    "        self.param['D']=dim\n",
    "        #encoder\n",
    "        self.hde=None\n",
    "        #classifier\n",
    "        self.hdc=None\n",
    "        # Initialize basis\n",
    "        basis = vanilla(self.param)\n",
    "        # make encoder based on basis\n",
    "        self.hde = HD_encoder(basis)\n",
    "        # Initialize classification hypervectors\n",
    "        self.hdc = HD_classifier(self.param[\"D\"], self.param[\"nClasses\"], 0)\n",
    "    def __call__(self, x : torch.Tensor):\n",
    "        #True iff the model has been trained\n",
    "        assert self.hde!=None and self.hdc!=None\n",
    "        #return predicted values\n",
    "        return self.predict(x)\n",
    "    def predict(self,x):\n",
    "        # print(x.shape)\n",
    "        #Get hypervectors for all data points\n",
    "        trainencoded=self.hde.encodeData(x)\n",
    "        #return predictions based on similarity to classification hypervectors\n",
    "        return np.array(self.hdc.predict(trainencoded))\n",
    "    def fit(self,traindata, trainlabels,\n",
    "                   epochs,\n",
    "                   regenloops,  # list of effective dimensions to reach \n",
    "                   percentDrop # drop/regen rate \n",
    "                    ):\n",
    "        \n",
    "        # find encoded training vectors\n",
    "        trainencoded = self.hde.encodeData(traindata)\n",
    "\n",
    "        # calculate amount of dropped dimensions based on percent and original dimension\n",
    "        amountDrop = int(percentDrop * self.hdc.D)#self.param.D?\n",
    "        # print(\"Updating times:\", regenloops)\n",
    "\n",
    "        for i in range(regenloops+1): # For each eDs to reach, will checkpoints\n",
    "            # print(\"regenloop: \" + str(i))\n",
    "            # train for x epochs\n",
    "            perfect=self.trainreploop(epochs,trainencoded,trainlabels)\n",
    "            #if its the last regeneration training, stop before doing another dimension drop; stop if 100% accuracy\n",
    "            if i==regenloops or perfect:\n",
    "                return #self.hdc,self.hde - unnecessary now that hdc and hde are within a class\n",
    "            # print(i)\n",
    "            #do the dimension drop and regeneration\n",
    "            trainencoded=self.regen(self.hde.basis,amountDrop,traindata)\n",
    "        return \"error\",\"error\"\n",
    "    \n",
    "    def trainreploop(self,epochs,trainencoded,trainlabels):\n",
    "        # Do the train \n",
    "        for j in range(epochs):\n",
    "            # do one pass of training\n",
    "            train_acc = 100 * self.hdc.fit(trainencoded, trainlabels, self.param)\n",
    "            #Test accuracy used to be in here but I took it out because we dont usually know it\n",
    "            print(\"Train: %.2f \\t \\t Test: \"%(train_acc))\n",
    "            # If accuracy is 100, finish\n",
    "            if train_acc == 100:\n",
    "                return True\n",
    "        return False\n",
    "    def regen(self,basis,amountDrop,traindata):\n",
    "        #make order of dimensions according to variaince; also store variances <-- unnecessary?\n",
    "        var, orders = self.hdc.evaluateBasis()\n",
    "        #drop dimensions with lowest variance\n",
    "        # print(sum(var)/len(var))\n",
    "        # plt.plot(range(0,len(var)),var[orders])\n",
    "        # plt.show()\n",
    "        \n",
    "        \n",
    "        toDrop = orders[:amountDrop]\n",
    "        if amountDrop<0:\n",
    "            toDrop = orders[-amountDrop:]\n",
    "        # print(\"Variances stats: max %.2f, min %.2f, mean %.2f\"%(max(var),min(var),np.mean(var)))\n",
    "        #update basis by randomizing dimension\n",
    "        updateBasis(basis,self.param,toDrop)\n",
    "        # move the new basis into the encoder\n",
    "        self.hde.updateBasis(basis)\n",
    "        # normalize previous classes so retrain has enough effect\n",
    "        self.hdc.updateClasses()\n",
    "        # get new encoded training data\n",
    "        return self.hde.encodeData(traindata)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies=[]\n",
    "for i in range(0,20):\n",
    "    model=NeuralHD(len(np.unique(y_test)),xtrain.shape[1],3000)\n",
    "    model.fit(xtrain,ytrain,5,5,.1)\n",
    "    accuracies=get_class_accuracy_breakdown(model,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00032916987639265694\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "        var, orders = model.hdc.evaluateBasis()\n",
    "        # drop dimensions with lowest variance\n",
    "        print(sum(var)/len(var))\n",
    "        plt.plot(range(0,len(var)),var[orders])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 68.34 \t \t Test: \n",
      "Train: 75.38 \t \t Test: \n",
      "Train: 77.57 \t \t Test: \n",
      "Train: 80.27 \t \t Test: \n",
      "Train: 80.95 \t \t Test: \n",
      "Train: 81.89 \t \t Test: \n",
      "Train: 83.61 \t \t Test: \n",
      "Train: 84.75 \t \t Test: \n",
      "Train: 85.02 \t \t Test: \n",
      "Train: 84.52 \t \t Test: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-e6b77365aff1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNeuralHD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-88-5333b8f6d8a9>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, traindata, trainlabels, epochs, regenloops, percentDrop)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;31m# print(i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;31m#do the dimension drop and regeneration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mtrainencoded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhde\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mamountDrop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraindata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"error\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"error\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-88-5333b8f6d8a9>\u001b[0m in \u001b[0;36mregen\u001b[0;34m(self, basis, amountDrop, traindata)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhdc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdateClasses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# get new encoded training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhde\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencodeData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraindata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-667377a8aced>\u001b[0m in \u001b[0;36mencodeData\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# encoded = np.cos(encoded)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;31m# print(encoded.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#encoded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;31m# start = time.time()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m#no matrix multiplication errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-667377a8aced>\u001b[0m in \u001b[0;36mencode\u001b[0;34m(x, basis, base, noise)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# we need batches to remove memory usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbsize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbsize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#h[i:i+bsize]=temp# torch.add(temp, self.base, out=h[i:i+bsize])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model=NeuralHD(len(np.unique(y_test)),xtrain.shape[1],3000)\n",
    "model.fit(xtrain,ytrain,10,1,.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0 accuracy: 0.7842639593908629\n",
      "points: 394\n",
      "class 1 accuracy: 0.9488\n",
      "points: 625\n",
      "class 2 accuracy: 0.9972789115646259\n",
      "points: 735\n",
      "class 3 accuracy: 0.1016949152542373\n",
      "points: 118\n",
      "class 4 accuracy: 0.0\n",
      "points: 8\n",
      "class 5 accuracy: 0.8602150537634409\n",
      "points: 186\n",
      "class 6 accuracy: 0.9519230769230769\n",
      "points: 104\n",
      "class 7 accuracy: 0.656441717791411\n",
      "points: 326\n",
      "class 8 accuracy: 0.9457013574660633\n",
      "points: 221\n",
      "0.8571954361428046\n"
     ]
    }
   ],
   "source": [
    "accuracies=[]\n",
    "points=[]\n",
    "for i in range (0,model.param['nClasses']):\n",
    "    yhat= model(x_test[y_test==i])\n",
    "    acc = (yhat==i).mean()\n",
    "    accuracies.append(acc)\n",
    "    points.append(len(yhat))\n",
    "    print('class '+str(i)+' accuracy: ' +str(acc))\n",
    "    print('points: '+ str(len(yhat)))\n",
    "print(sum([accuracies[i]*points[i] for i in range(0,len(accuracies))])/sum(points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8789105631210894"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropoutratios=[.8,.6,.4,.2]\n",
    "valaccuracies=[]\n",
    "accuracies=[]\n",
    "models=[]\n",
    "for i in range(0,10):\n",
    "    setup=\"model=NeuralHD(len(np.unique(y_test)),xtrain.shape[1],\"+ str(dimension) +\")\"\n",
    "    exec(setup)\n",
    "    for dropoutratio in dropoutratios:\n",
    "        training=\"model.fit(xtrain[:],ytrain[:],\"+str(4)+\",\"+str(1)+\",\"+str(dropoutratio)+\")\" #6,10\n",
    "        exec(training)\n",
    "        # var, orders = model.hdc.evaluateBasis()\n",
    "        # drop dimensions with lowest variance\n",
    "        # print(sum(var)/len(var))\n",
    "        # plt.plot(range(0,len(var)),var[orders])\n",
    "        # plt.show()\n",
    "    print(\"Experiment\"+str(i))\n",
    "    print(\"Validation\")\n",
    "    valaccuracies.append(get_class_accuracy_breakdown(model,xtrain[7000:],ytrain[7000:]))\n",
    "    accuracies.append(get_class_accuracy_breakdown(model,x_test,y_test))\n",
    "    models.append(copy.deepcopy(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dropoutratios=[.8,.6,.4,.2,.1]\n",
    "setup=\"model=NeuralHD(len(np.unique(y_test)),xtrain.shape[1],\"+ str(dimension) +\")\"\n",
    "exec(setup)\n",
    "accuracies=[]\n",
    "for dropoutratio in dropoutratios:\n",
    "    valaccuracies=[]\n",
    "    # accuracies=[]\n",
    "    models=[]\n",
    "    for i in range(0,5):\n",
    "        newmodel=copy.deepcopy(model)\n",
    "        training=\"newmodel.fit(xtrain[:7000],ytrain[:7000],\"+str(10)+\",\"+str(1)+\",\"+str(dropoutratio)+\")\" #6,10\n",
    "        exec(training)\n",
    "        print(\"validating\")\n",
    "        valaccuracies.append(get_class_accuracy_breakdown(newmodel,xtrain[7000:],ytrain[7000:]))\n",
    "        models.append(copy.deepcopy(newmodel))\n",
    "    if len(accuracies)==0 or max(valaccuracies)>accuracies[-1]:\n",
    "        model=models[valaccuracies.index(max(valaccuracies))]\n",
    "    print(\"Testing\")\n",
    "    accuracies.append(get_class_accuracy_breakdown(model,x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.037"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.param['lr']"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
